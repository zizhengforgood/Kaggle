### SETI总结

输入输出

- 原始图像6通道，3个含检测信号，3个为背景噪声。
- 输出图像中含有外星信号的概率 0~1
- 评估标准，ROC 的 AUC

基线模型

- efficientnet_b0_ns, bs (batchsize) 128, adamw 1e-3, 20 epoch, 5folds，320分辨率
- mixup = 0.1
- 性能，本地交叉验证83.9，竞赛测试集73.0

涨点策略 及原因

- 五折集成涨点1%，数据集按80% 20%切分。
- 去掉旋转数据增强 涨点0.5%
- 高分辨率：320 --> 512 -->832 --> 1024
  - 512提升2%， 832提升3%分数， 1024提升3.1% 因此选832
  - 原始图片大小819*256， 因此大于832的图片信息都是插值得来的，提升小。
  - 直接用832*256，因为预训练权重在方的图片上训练，结果不好，放弃。
- mixup = 2
  - 网格搜索mixup = {0.1， 0.2， 0.5， 1， 2， 5， 10}
  - 2效果最好，即大量等比例混合能提升性能。+0.5%
- 全连接层个数及参数 （**到目前为止 LB 77.6**）
  - 原始为1层，增加一层之后+1%
  - 搜索增加层数{1， 2， 3}， 神经元个数{128， 256， 512， 1024}
  - 更深的层数和更多的神经元趋向于轻微提升 +0.05%~0.10%，没必要，故最终用1层512
  - dropout搜索{0，0.2， 0.5， 0.8}
  - 在b0上0表现出更好的单折性能，但TTA结果与0.5相似。最终0与0.5混用。
- 大batchsize或者更多的epoch
  - 单独增加batchsize到192，涨点0.4%，考虑因为mixup更充分混合。
  - 单独增加epoch到60（从20），涨点0.1%，说明20epoch基本足够。
- 学习率搜索 (**LB 78.0**)
  - 优化器{sgd, adam, adamw}, 学习率{3e-2, 1e-2 ... 3e-6, 1e-6}, 衰减策略{onecycle, cosine}
  - adamw 最优值在3e-3 ~ 1e-3之间，onecycle优于cosine，最终用1.75e-3
- 测试时数据增强
  - 测试时水平垂直翻转数据 + 0.3%
  - 不同分辨率测试，不稳定，在b0上 + 0.1%，最后混用。
- 更大的模型 (**78.7**)
  - 更换模型为efficientnetv2_m +0.5%
- 使用旧数据（**78.9**）
  - 添加旧数据集正例，或者调整目前训练正例和负例比例为1：5 +0.2%
- 伪标签 （**79.4**）
  - 用模型预测的结果作为测试集的标签，把网络再训练一遍
- 集成 （**79.6**）
  - 集成了efficiennetb0, b4, tf_efficientnet_v2m, 三个模型，分辨率832和928的结果。



未涨点

- focal loss 搜索alpha和gamma{0.1， 0.5， 0.9， 0.5， 1， 2}，最好的涨0.1%，未用。
- labelsmooth，搜索gamma{0.1， 0.2， 0.3}，无变化，未用。
- 搜索cutout，resize插值为bicubic，平移，放缩大小，发现默认0.2最佳，cutout不加。
- 输入数据相关
  - 图像是有276，3的图像拼接成819，对拼接方法进行shuffle，无变化
  - 用三通道的图片，降低0.5%
  - 用六通道的图片，拼接或者不拼接都降低0.5%
  - 加个自定义网络头，将图片resize到1024，无显著变化。
- 其他网络结构
  - transformer 只支持384，很难收敛，需要较小的学习率。
  - densenet，regnet，skresnet等最终未收敛。
  - nfnet，hrnet在cv上比effnet高，但lb上表现相似。训练时间是effnet的三倍，弃用。
- domain adaption
  - dsan 降低精度7%
- 梯度切片，加了收敛快，但降低0.2%

其他

- 使用混精度训练加速训练
- 使用cudnn后端加速训练
- 随机数种子无法在不同机器上确保随机。
- 五折交叉验证保持结果的稳定和可信性，单折波动上下1.5%

