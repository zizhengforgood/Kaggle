{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://uku28motab.feishu.cn/docs/doccnUDbEhudHm2V440lcY87B1c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vietnamese-nursery",
    "papermill": {
     "duration": 0.017372,
     "end_time": "2021-05-11T19:26:26.916863",
     "exception": false,
     "start_time": "2021-05-11T19:26:26.899491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyldEJ_jq4yx"
   },
   "outputs": [],
   "source": [
    "# 数据读取\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:27.117055Z",
     "iopub.status.busy": "2021-05-11T19:26:27.116234Z",
     "iopub.status.idle": "2021-05-11T19:26:27.914773Z",
     "shell.execute_reply": "2021-05-11T19:26:27.913854Z"
    },
    "id": "nearby-expert",
    "papermill": {
     "duration": 0.828531,
     "end_time": "2021-05-11T19:26:27.914917",
     "exception": false,
     "start_time": "2021-05-11T19:26:27.086386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将数据划分为5份\n",
    "from sklearn import model_selection\n",
    "def create_folds(data, num_splits):\n",
    "    data[\"kfold\"] = -1\n",
    "    kf = model_selection.KFold(n_splits=num_splits, shuffle=True, random_state=2021)\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=data)):\n",
    "        data.loc[v_, 'kfold'] = f\n",
    "    return data\n",
    "train = create_folds(train, num_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "legal-float",
    "papermill": {
     "duration": 0.017397,
     "end_time": "2021-05-11T19:26:27.950181",
     "exception": false,
     "start_time": "2021-05-11T19:26:27.932784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import Dependencies - Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:27.992516Z",
     "iopub.status.busy": "2021-05-11T19:26:27.991711Z",
     "iopub.status.idle": "2021-05-11T19:26:27.994184Z",
     "shell.execute_reply": "2021-05-11T19:26:27.993779Z"
    },
    "id": "complete-breakdown",
    "papermill": {
     "duration": 0.026039,
     "end_time": "2021-05-11T19:26:27.994289",
     "exception": false,
     "start_time": "2021-05-11T19:26:27.96825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入相关库\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "willing-affairs",
    "papermill": {
     "duration": 7.228235,
     "end_time": "2021-05-11T19:26:35.239965",
     "exception": false,
     "start_time": "2021-05-11T19:26:28.01173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import (\n",
    "    Dataset, DataLoader, \n",
    "    SequentialSampler, RandomSampler\n",
    ")\n",
    "from transformers import AutoConfig\n",
    "from transformers import (\n",
    "    get_cosine_schedule_with_warmup, \n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from transformers import AdamW\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "palestinian-immunology",
    "papermill": {
     "duration": 0.020552,
     "end_time": "2021-05-11T19:26:35.281616",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.261064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert Examples to Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:35.328454Z",
     "iopub.status.busy": "2021-05-11T19:26:35.32758Z",
     "iopub.status.idle": "2021-05-11T19:26:35.329972Z",
     "shell.execute_reply": "2021-05-11T19:26:35.330375Z"
    },
    "id": "irish-fossil",
    "papermill": {
     "duration": 0.028976,
     "end_time": "2021-05-11T19:26:35.330531",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.301555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将样本转化成特征,并返回\n",
    "def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
    "    # 替换文中的换行符\n",
    "    data = data.replace('\\n', '')\n",
    "    # 分词器编码\n",
    "    tok = tokenizer.encode_plus(\n",
    "        data, \n",
    "        max_length=max_len, \n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    curr_sent = {}\n",
    "    padding_length = max_len - len(tok['input_ids'])\n",
    "    curr_sent['input_ids'] = tok['input_ids'] + ([tokenizer.pad_token_id] * padding_length)\n",
    "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
    "        ([0] * padding_length)\n",
    "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
    "        ([0] * padding_length)\n",
    "    return curr_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "subject-entertainment",
    "papermill": {
     "duration": 0.019304,
     "end_time": "2021-05-11T19:26:35.369266",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.349962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:35.41671Z",
     "iopub.status.busy": "2021-05-11T19:26:35.415851Z",
     "iopub.status.idle": "2021-05-11T19:26:35.418118Z",
     "shell.execute_reply": "2021-05-11T19:26:35.41868Z"
    },
    "id": "solar-group",
    "papermill": {
     "duration": 0.029976,
     "end_time": "2021-05-11T19:26:35.418819",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.388843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据集寻回\n",
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
    "        self.data = data\n",
    "        if 'excerpt' in self.data.columns:\n",
    "            self.excerpts = self.data.excerpt.values.tolist()\n",
    "        else:\n",
    "            self.excerpts = self.data.text.values.tolist()\n",
    "        self.targets = self.data.target.values.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "        self.max_len = max_len\n",
    "    # 返回文本长度\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    # 获取项（item）中各参数信息\n",
    "    def __getitem__(self, item):\n",
    "        excerpt, label = self.excerpts[item], self.targets[item]\n",
    "        features = convert_examples_to_features(\n",
    "            excerpt, self.tokenizer, \n",
    "            self.max_len, self.is_test\n",
    "        )\n",
    "        return {\n",
    "            'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "            'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "            'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "            'label':torch.tensor(label, dtype=torch.double),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "proprietary-genre",
    "papermill": {
     "duration": 0.01885,
     "end_time": "2021-05-11T19:26:35.456835",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.437985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:35.51111Z",
     "iopub.status.busy": "2021-05-11T19:26:35.510248Z",
     "iopub.status.idle": "2021-05-11T19:26:35.512883Z",
     "shell.execute_reply": "2021-05-11T19:26:35.512449Z"
    },
    "id": "resident-kazakhstan",
    "papermill": {
     "duration": 0.037145,
     "end_time": "2021-05-11T19:26:35.512991",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.475846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将模型设计成类的形式\n",
    "class CommonLitModel(nn.Module):\n",
    "    初始化\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name, \n",
    "        config,  \n",
    "        multisample_dropout=False,\n",
    "        output_hidden_states=False\n",
    "    ):\n",
    "        super(CommonLitModel, self).__init__()\n",
    "        self.config = config\n",
    "        self.roberta = AutoModel.from_pretrained(\n",
    "            model_name, \n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "        if multisample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(0.5) for _ in range(5)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n",
    "        #self.regressor = nn.Linear(config.hidden_size*2, 1)\n",
    "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "        self._init_weights(self.layer_norm)\n",
    "        self._init_weights(self.regressor)\n",
    "    \n",
    "    # 定义初始化权重\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    # 前向传播\n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        sequence_output = outputs[1]\n",
    "        sequence_output = self.layer_norm(sequence_output)\n",
    " \n",
    "        # max-avg head 最大平均多头(并联了max pool和 mean pool的结果)\n",
    "        # average_pool = torch.mean(sequence_output, 1)\n",
    "        # max_pool, _ = torch.max(sequence_output, 1)\n",
    "        # concat_sequence_output = torch.cat((average_pool, max_pool), 1)\n",
    " \n",
    "        # 多样本 dropout\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                logits = self.regressor(dropout(sequence_output))\n",
    "            else:\n",
    "                logits += self.regressor(dropout(sequence_output))\n",
    "        \n",
    "        logits /= len(self.dropouts)\n",
    " \n",
    "        # 计算损失值\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # regression task\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
    "        \n",
    "        output = (logits,) + outputs[2:]\n",
    "        return ((loss,) + output) if loss is not None else output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "going-tractor",
    "papermill": {
     "duration": 0.019467,
     "end_time": "2021-05-11T19:26:35.552336",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.532869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Lamb Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:35.608787Z",
     "iopub.status.busy": "2021-05-11T19:26:35.608039Z",
     "iopub.status.idle": "2021-05-11T19:26:35.610861Z",
     "shell.execute_reply": "2021-05-11T19:26:35.610406Z"
    },
    "id": "photographic-crack",
    "papermill": {
     "duration": 0.039162,
     "end_time": "2021-05-11T19:26:35.610963",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.571801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lamb优化器\n",
    "class Lamb(Optimizer):\n",
    "    # 代码参考来源: https://github.com/cybertronai/pytorch-lamb\n",
    "    # 参数初始化\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,\n",
    "        lr: float = 1e-3,\n",
    "        betas = (0.9, 0.999),\n",
    "        eps: float = 1e-6,\n",
    "        weight_decay: float = 0,\n",
    "        clamp_value: float = 10,\n",
    "        adam: bool = False,\n",
    "        debias: bool = False,\n",
    "    ):\n",
    "        if lr <= 0.0:\n",
    "            raise ValueError('Invalid learning rate: {}'.format(lr))\n",
    "        if eps < 0.0:\n",
    "            raise ValueError('Invalid epsilon value: {}'.format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\n",
    "                'Invalid beta parameter at index 0: {}'.format(betas[0])\n",
    "            )\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\n",
    "                'Invalid beta parameter at index 1: {}'.format(betas[1])\n",
    "            )\n",
    "        if weight_decay < 0:\n",
    "            raise ValueError(\n",
    "                'Invalid weight_decay value: {}'.format(weight_decay)\n",
    "            )\n",
    "        if clamp_value < 0.0:\n",
    "            raise ValueError('Invalid clamp value: {}'.format(clamp_value))\n",
    "\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.clamp_value = clamp_value\n",
    "        self.adam = adam\n",
    "        self.debias = debias\n",
    "\n",
    "        super(Lamb, self).__init__(params, defaults)\n",
    "    # 损失函数计算步骤\n",
    "    def step(self, closure = None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                # 如果梯度是稀疏的，就报Lamb不支持稀疏梯度\n",
    "                if grad.is_sparse:\n",
    "                    msg = (\n",
    "                        'Lamb does not support sparse gradients, '\n",
    "                        'please consider SparseAdam instead'\n",
    "                    )\n",
    "                    raise RuntimeError(msg)\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # 状态初始化\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    # 梯度值的指数移动平均\n",
    "                    state['exp_avg'] = torch.zeros_like(\n",
    "                        p, memory_format=torch.preserve_format\n",
    "                    )\n",
    "                    # 梯度值平方的指数移动平均\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(\n",
    "                        p, memory_format=torch.preserve_format\n",
    "                    )\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                # 衰减一、二阶矩运行平均系数\n",
    "                # m_t\n",
    "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
    "                # v_t\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
    "\n",
    "                # Paper v3 不需要使用去偏置.(debias=1 去偏置，debias=0不去偏置, 默认debias为0)\n",
    "                if self.debias:\n",
    "                    bias_correction = math.sqrt(1 - beta2 ** state['step'])\n",
    "                    bias_correction /= 1 - beta1 ** state['step']\n",
    "                else:\n",
    "                    bias_correction = 1\n",
    "\n",
    "                # 对lr应用偏差以避免boardcase。\n",
    "                step_size = group['lr'] * bias_correction\n",
    "                # 权重的取值范围在0, clamp_value之间\n",
    "                weight_norm = torch.norm(p.data).clamp(0, self.clamp_value)\n",
    "\n",
    "                adam_step = exp_avg / exp_avg_sq.sqrt().add(group['eps'])\n",
    "                if group['weight_decay'] != 0:\n",
    "                    adam_step.add_(p.data, alpha=group['weight_decay'])\n",
    "\n",
    "                adam_norm = torch.norm(adam_step)\n",
    "                if weight_norm == 0 or adam_norm == 0:\n",
    "                    trust_ratio = 1\n",
    "                else:\n",
    "                    trust_ratio = weight_norm / adam_norm\n",
    "                state['weight_norm'] = weight_norm\n",
    "                state['adam_norm'] = adam_norm\n",
    "                state['trust_ratio'] = trust_ratio\n",
    "                if self.adam:\n",
    "                    trust_ratio = 1\n",
    "\n",
    "                p.data.add_(adam_step, alpha=-step_size * trust_ratio)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exceptional-asbestos",
    "papermill": {
     "duration": 0.019229,
     "end_time": "2021-05-11T19:26:35.648664",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.629435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Differential Learning Rate and Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:35.700523Z",
     "iopub.status.busy": "2021-05-11T19:26:35.69983Z",
     "iopub.status.idle": "2021-05-11T19:26:35.702594Z",
     "shell.execute_reply": "2021-05-11T19:26:35.702187Z"
    },
    "id": "worth-distance",
    "papermill": {
     "duration": 0.034924,
     "end_time": "2021-05-11T19:26:35.702699",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.667775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 获取优化器参数，以及使用分层学习率方法得到权重\n",
    "def get_optimizer_params(model):\n",
    "    # 分层学习率和权重衰减（学习率按照0-3,4-7,8-11分成了3层）\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    learning_rate = 5e-5\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    group1=['layer.0.','layer.1.','layer.2.','layer.3.']\n",
    "    group2=['layer.4.','layer.5.','layer.6.','layer.7.']    \n",
    "    group3=['layer.8.','layer.9.','layer.10.','layer.11.']\n",
    "    group_all=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.','layer.8.','layer.9.','layer.10.','layer.11.']\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.01, 'lr': learning_rate/2.6},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.01, 'lr': learning_rate},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.01, 'lr': learning_rate*2.6},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.0, 'lr': learning_rate/2.6},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.0, 'lr': learning_rate},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.0, 'lr': learning_rate*2.6},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"roberta\" not in n], 'lr':1e-3, \"momentum\" : 0.99},\n",
    "    ]\n",
    "    return optimizer_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "respiratory-improvement",
    "papermill": {
     "duration": 0.018135,
     "end_time": "2021-05-11T19:26:35.739429",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.721294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:35.788703Z",
     "iopub.status.busy": "2021-05-11T19:26:35.787892Z",
     "iopub.status.idle": "2021-05-11T19:26:35.79056Z",
     "shell.execute_reply": "2021-05-11T19:26:35.790141Z"
    },
    "id": "ahead-steering",
    "papermill": {
     "duration": 0.032912,
     "end_time": "2021-05-11T19:26:35.790678",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.757766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取预训练模型参数，返回预训练模型参数和分词器\n",
    "def make_model(model_name='../content/roberta-base-5-epochs/', num_labels=1):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    config.update({'num_labels':num_labels})\n",
    "    model = CommonLitModel(model_name, config=config)\n",
    "    return model, tokenizer\n",
    "\n",
    "# \n",
    "def make_optimizer(model, optimizer_name=\"AdamW\"):\n",
    "    # 读取优化器参数 \n",
    "    optimizer_grouped_parameters = get_optimizer_params(model)\n",
    "    kwargs = {\n",
    "            'lr':5e-5,\n",
    "            'weight_decay':0.01,\n",
    "            # 'betas': (0.9, 0.98),\n",
    "            # 'eps': 1e-06\n",
    "    }\n",
    "    # 分别实验不同的优化器的优化结果，其中AdamW具有最好结果\n",
    "    if optimizer_name == \"LAMB\":\n",
    "        optimizer = Lamb(optimizer_grouped_parameters, **kwargs)\n",
    "        return optimizer\n",
    "    elif optimizer_name == \"Adam\":\n",
    "        from torch.optim import Adam\n",
    "        optimizer = Adam(optimizer_grouped_parameters, **kwargs)\n",
    "        return optimizer\n",
    "    elif optimizer_name == \"AdamW\":\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, **kwargs)\n",
    "        return optimizer\n",
    "    else:\n",
    "        raise Exception('Unknown optimizer: {}'.format(optimizer_name))\n",
    "# 使用不同的权重衰减方式，其中最优的是cosine_warmup\n",
    "def make_scheduler(optimizer, decay_name='linear', t_max=None, warmup_steps=None):\n",
    "    if decay_name == 'step':\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer,\n",
    "            milestones=[30, 60, 90],\n",
    "            gamma=0.1\n",
    "        )\n",
    "    elif decay_name == 'cosine':\n",
    "        scheduler = lrs.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=t_max\n",
    "        )\n",
    "    elif decay_name == \"cosine_warmup\":\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=t_max\n",
    "        )\n",
    "    elif decay_name == \"linear\":\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=warmup_steps, \n",
    "            num_training_steps=t_max\n",
    "        )\n",
    "    else:\n",
    "        raise Exception('Unknown lr scheduler: {}'.format(decay_type))    \n",
    "    return scheduler    \n",
    "# 读取处理好的文本，通过DataLoader转换成张量传入模型中\n",
    "def make_loader(\n",
    "    data, \n",
    "    tokenizer, \n",
    "    max_len,\n",
    "    batch_size,\n",
    "    fold=0\n",
    "):\n",
    "    train_set, valid_set = data[data['kfold']!=fold], data[data['kfold']==fold]\n",
    "    train_dataset = DatasetRetriever(train_set, tokenizer, max_len)\n",
    "    valid_dataset = DatasetRetriever(valid_set, tokenizer, max_len)\n",
    "\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        sampler=train_sampler, \n",
    "        pin_memory=True, \n",
    "        drop_last=False, \n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_sampler = SequentialSampler(valid_dataset)\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=batch_size // 2, \n",
    "        sampler=valid_sampler, \n",
    "        pin_memory=True, \n",
    "        drop_last=False, \n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "written-resort",
    "papermill": {
     "duration": 0.018561,
     "end_time": "2021-05-11T19:26:35.827595",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.809034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:35.870815Z",
     "iopub.status.busy": "2021-05-11T19:26:35.870145Z",
     "iopub.status.idle": "2021-05-11T19:26:35.872923Z",
     "shell.execute_reply": "2021-05-11T19:26:35.872518Z"
    },
    "id": "changed-monte",
    "papermill": {
     "duration": 0.027034,
     "end_time": "2021-05-11T19:26:35.873026",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.845992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "class AverageMeter(object):\n",
    "    # 设定初始化函数\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    # 初始化参数\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.max = 0\n",
    "        self.min = 1e5\n",
    "    # 参数更新\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        if val > self.max:\n",
    "            self.max = val\n",
    "        if val < self.min:\n",
    "            self.min = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atmospheric-correspondence",
    "papermill": {
     "duration": 0.01885,
     "end_time": "2021-05-11T19:26:35.910429",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.891579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:35.960435Z",
     "iopub.status.busy": "2021-05-11T19:26:35.959727Z",
     "iopub.status.idle": "2021-05-11T19:26:35.962459Z",
     "shell.execute_reply": "2021-05-11T19:26:35.962067Z"
    },
    "id": "chubby-liberty",
    "papermill": {
     "duration": 0.033486,
     "end_time": "2021-05-11T19:26:35.962579",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.929093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练程序\n",
    "class Trainer:\n",
    "    # 初始化\n",
    "    def __init__(self, model, optimizer, scheduler, scalar=None, log_interval=1, evaluate_interval=1):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.scalar = scalar\n",
    "        self.log_interval = log_interval\n",
    "        self.evaluate_interval = evaluate_interval\n",
    "        self.evaluator = Evaluator(self.model, self.scalar)\n",
    "    # 训练并记录训练损失\n",
    "    def train(self, train_loader, valid_loader, epoch, \n",
    "              result_dict, tokenizer, fold):\n",
    "        count = 0\n",
    "        losses = AverageMeter()\n",
    "        self.model.train()\n",
    "        \n",
    "        for batch_idx, batch_data in enumerate(train_loader):\n",
    "            input_ids, attention_mask, token_type_ids, labels = batch_data['input_ids'], \\\n",
    "                batch_data['attention_mask'], batch_data['token_type_ids'], batch_data['label']\n",
    "            input_ids, attention_mask, token_type_ids, labels = \\\n",
    "                input_ids.cuda(), attention_mask.cuda(), token_type_ids.cuda(), labels.cuda()\n",
    "            \n",
    "            if self.scalar is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        labels=labels\n",
    "                    )\n",
    "            else:\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    labels=labels\n",
    "                )\n",
    "\n",
    "            loss, logits = outputs[:2]\n",
    "            count += labels.size(0)\n",
    "            losses.update(loss.item(), input_ids.size(0))\n",
    "            \n",
    "            if self.scalar is not None:\n",
    "                self.scalar.scale(loss).backward()\n",
    "                self.scalar.step(self.optimizer)\n",
    "                self.scalar.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            self.scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            if batch_idx % self.log_interval == 0:\n",
    "                _s = str(len(str(len(train_loader.sampler))))\n",
    "                ret = [\n",
    "                    ('epoch: {:0>3} [{: >' + _s + '}/{} ({: >3.0f}%)]').format(epoch, count, len(train_loader.sampler), 100 * count / len(train_loader.sampler)),\n",
    "                    'train_loss: {: >4.5f}'.format(losses.avg),\n",
    "                ]\n",
    "                print(', '.join(ret))\n",
    "            \n",
    "            if batch_idx % self.evaluate_interval == 0:\n",
    "                result_dict = self.evaluator.evaluate(\n",
    "                    valid_loader, \n",
    "                    epoch, \n",
    "                    result_dict, \n",
    "                    tokenizer\n",
    "                )\n",
    "                if result_dict['val_loss'][-1] < result_dict['best_val_loss']:\n",
    "                    print(\"{} epoch, best epoch was updated! valid_loss: {: >4.5f}\".format(epoch, result_dict['val_loss'][-1]))\n",
    "                    result_dict[\"best_val_loss\"] = result_dict['val_loss'][-1]\n",
    "                    torch.save(self.model.state_dict(), f\"model{fold}.bin\")\n",
    "\n",
    "        result_dict['train_loss'].append(losses.avg)\n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interested-glass",
    "papermill": {
     "duration": 0.019241,
     "end_time": "2021-05-11T19:26:36.000319",
     "exception": false,
     "start_time": "2021-05-11T19:26:35.981078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:36.052351Z",
     "iopub.status.busy": "2021-05-11T19:26:36.05141Z",
     "iopub.status.idle": "2021-05-11T19:26:36.054072Z",
     "shell.execute_reply": "2021-05-11T19:26:36.053643Z"
    },
    "id": "demonstrated-delhi",
    "papermill": {
     "duration": 0.034578,
     "end_time": "2021-05-11T19:26:36.054175",
     "exception": false,
     "start_time": "2021-05-11T19:26:36.019597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    # 初始化变量\n",
    "    def __init__(self, model, scalar=None):\n",
    "        self.model = model\n",
    "        self.scalar = scalar\n",
    "    # 初始化参数\n",
    "    def worst_result(self):\n",
    "        ret = {\n",
    "            'loss':float('inf'),\n",
    "            'accuracy':0.0\n",
    "        }\n",
    "        return ret\n",
    "    # 结果转换成字符串\n",
    "    def result_to_str(self, result):\n",
    "        ret = [\n",
    "            'epoch: {epoch:0>3}',\n",
    "            'loss: {loss: >4.2e}'\n",
    "        ]\n",
    "        for metric in self.evaluation_metrics:\n",
    "            ret.append('{}: {}'.format(metric.name, metric.fmtstr))\n",
    "        return ', '.join(ret).format(**result)\n",
    "\n",
    "    def save(self, result):\n",
    "        with open('result_dict.json', 'w') as f:\n",
    "            f.write(json.dumps(result, sort_keys=True, indent=4, ensure_ascii=False))\n",
    "    \n",
    "    def load(self):\n",
    "        result = self.worst_result\n",
    "        if os.path.exists('result_dict.json'):\n",
    "            with open('result_dict.json', 'r') as f:\n",
    "                try:\n",
    "                    result = json.loads(f.read())\n",
    "                except:\n",
    "                    pass\n",
    "        return result\n",
    "    # 验证模型并记录验证结果\n",
    "    def evaluate(self, data_loader, epoch, result_dict, tokenizer):\n",
    "        losses = AverageMeter()\n",
    "\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_data in enumerate(data_loader):\n",
    "                input_ids, attention_mask, token_type_ids, labels = batch_data['input_ids'], \\\n",
    "                    batch_data['attention_mask'], batch_data['token_type_ids'], batch_data['label']\n",
    "                input_ids, attention_mask, token_type_ids, labels = input_ids.cuda(), \\\n",
    "                    attention_mask.cuda(), token_type_ids.cuda(), labels.cuda()\n",
    "                \n",
    "                if self.scalar is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = self.model(\n",
    "                            input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            labels=labels\n",
    "                        )\n",
    "                else:\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        labels=labels\n",
    "                    )\n",
    "                \n",
    "                loss, logits = outputs[:2]\n",
    "                losses.update(loss.item(), input_ids.size(0))\n",
    "\n",
    "        print('----Validation Results Summary----')\n",
    "        print('Epoch: [{}] valid_loss: {: >4.5f}'.format(epoch, losses.avg))\n",
    "\n",
    "        result_dict['val_loss'].append(losses.avg)        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "solved-ownership",
    "papermill": {
     "duration": 0.018509,
     "end_time": "2021-05-11T19:26:36.091323",
     "exception": false,
     "start_time": "2021-05-11T19:26:36.072814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:36.136292Z",
     "iopub.status.busy": "2021-05-11T19:26:36.135577Z",
     "iopub.status.idle": "2021-05-11T19:26:36.137828Z",
     "shell.execute_reply": "2021-05-11T19:26:36.138253Z"
    },
    "id": "addressed-function",
    "papermill": {
     "duration": 0.028282,
     "end_time": "2021-05-11T19:26:36.138369",
     "exception": false,
     "start_time": "2021-05-11T19:26:36.110087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 配置参数\n",
    "def config(fold=0):\n",
    "    torch.manual_seed(2021)\n",
    "    torch.cuda.manual_seed(2021)\n",
    "    torch.cuda.manual_seed_all(2021)\n",
    "    epochs = 8\n",
    "    max_len = 250\n",
    "    batch_size = 16\n",
    "    # 读取预训练模型\n",
    "    model, tokenizer = make_model(model_name='../content/roberta-base-5-epochs/', num_labels=1)\n",
    "    train_loader, valid_loader = make_loader(\n",
    "        train, tokenizer, max_len=max_len,\n",
    "        batch_size=batch_size, fold=fold\n",
    "    )\n",
    "\n",
    "    import math\n",
    "    # 每轮step数\n",
    "    num_update_steps_per_epoch = len(train_loader)\n",
    "    max_train_steps = epochs * num_update_steps_per_epoch\n",
    "    warmup_proportion = 0\n",
    "    if warmup_proportion != 0:\n",
    "        warmup_steps = math.ceil((max_train_steps * 2) / 100)\n",
    "    else:\n",
    "        warmup_steps = 0\n",
    "    # 获取相应的优化器参数\n",
    "    optimizer = make_optimizer(model, \"AdamW\")\n",
    "    scheduler = make_scheduler(\n",
    "        optimizer, decay_name='cosine_warmup', \n",
    "        t_max=max_train_steps, \n",
    "        warmup_steps=warmup_steps\n",
    "    )    \n",
    "    # \n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
    "            torch.cuda.device_count(), \n",
    "            torch.cuda.get_device_name(0))\n",
    "        )\n",
    "        model = model.cuda() \n",
    "    else:\n",
    "        raise ValueError('CPU training is not supported')\n",
    "\n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    scaler = None\n",
    "    # 保存模型参数\n",
    "    result_dict = {\n",
    "        'epoch':[], \n",
    "        'train_loss': [], \n",
    "        'val_loss' : [], \n",
    "        'best_val_loss': np.inf\n",
    "    }\n",
    "    return (\n",
    "        model, tokenizer, \n",
    "        optimizer, scheduler, \n",
    "        scaler, train_loader, \n",
    "        valid_loader, result_dict, \n",
    "        epochs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nonprofit-causing",
    "papermill": {
     "duration": 0.020208,
     "end_time": "2021-05-11T19:26:36.177987",
     "exception": false,
     "start_time": "2021-05-11T19:26:36.157779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:36.227481Z",
     "iopub.status.busy": "2021-05-11T19:26:36.226678Z",
     "iopub.status.idle": "2021-05-11T19:26:36.229314Z",
     "shell.execute_reply": "2021-05-11T19:26:36.228849Z"
    },
    "id": "suspended-anniversary",
    "papermill": {
     "duration": 0.032278,
     "end_time": "2021-05-11T19:26:36.229422",
     "exception": false,
     "start_time": "2021-05-11T19:26:36.197144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 运行\n",
    "def run(fold=0):\n",
    "    # 读取参数\n",
    "    model, tokenizer, optimizer, scheduler, scaler, \\\n",
    "        train_loader, valid_loader, result_dict, epochs = config(fold)\n",
    "    # 训练\n",
    "    import time\n",
    "    trainer = Trainer(model, optimizer, scheduler, scaler)\n",
    "    # 初始化训练时间 \n",
    "    train_time_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        result_dict['epoch'] = epoch\n",
    "        # 等待参数完成\n",
    "        torch.cuda.synchronize()\n",
    "        # 记录开始时间\n",
    "        tic1 = time.time()\n",
    "        # 记录训练和验证结果\n",
    "        result_dict = trainer.train(train_loader, valid_loader, epoch, \n",
    "                                    result_dict, tokenizer, fold)\n",
    "        # 等待参数完成\n",
    "        torch.cuda.synchronize()\n",
    "        # 记录结束时间\n",
    "        tic2 = time.time() \n",
    "        # 计算运行时间\n",
    "        train_time_list.append(tic2 - tic1)\n",
    "    # 删除模型，分词器，优化器，衰减参数，训练数据，验证数据\n",
    "    torch.cuda.empty_cache()\n",
    "    del model, tokenizer, optimizer, scheduler, \\\n",
    "        scaler, train_loader, valid_loader,\n",
    "    # 释放内存\n",
    "    gc.collect()\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T19:26:36.272151Z",
     "iopub.status.busy": "2021-05-11T19:26:36.271631Z",
     "iopub.status.idle": "2021-05-11T20:15:37.136995Z",
     "shell.execute_reply": "2021-05-11T20:15:37.137733Z"
    },
    "id": "flush-clause",
    "outputId": "0bb37720-4c50-4662-8128-176e7008e03d",
    "papermill": {
     "duration": 2940.88873,
     "end_time": "2021-05-11T20:15:37.137957",
     "exception": false,
     "start_time": "2021-05-11T19:26:36.249227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_list = []\n",
    "# 记录每折中的结果\n",
    "for fold in range(5):\n",
    "    print('----')\n",
    "    print(f'FOLD: {fold}')\n",
    "    result_dict = run(fold)\n",
    "    result_list.append(result_dict)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Validation Loss per Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lt2jASMiPH1R",
    "outputId": "473119ae-40c4-4b31-fa9a-b6c42feaf3fb"
   },
   "outputs": [],
   "source": [
    "[print(\"FOLD::\", i, \"Loss:: \", fold['best_val_loss']) for i, fold in enumerate(result_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOF Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aaj35kCjxzT",
    "outputId": "a1830cca-986e-4797-d4ee-06466df3e0d3"
   },
   "outputs": [],
   "source": [
    "# OOF预测\n",
    "oof = np.zeros(len(train))\n",
    "for fold in tqdm(range(5), total=5):\n",
    "    model, tokenizer = make_model()\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'model{fold}.bin')\n",
    "    )\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    val_index = train[train.kfold==fold].index.tolist()\n",
    "    train_loader, val_loader = make_loader(train, tokenizer, 250, 16, fold=fold)\n",
    "    # scalar = torch.cuda.amp.GradScaler()\n",
    "    scalar = None\n",
    "    # 预测结果\n",
    "    preds = []\n",
    "    for index, data in enumerate(val_loader):\n",
    "        input_ids, attention_mask, token_type_ids, labels = data['input_ids'], \\\n",
    "            data['attention_mask'], data['token_type_ids'], data['label']\n",
    "        input_ids, attention_mask, token_type_ids, labels = input_ids.cuda(), \\\n",
    "            attention_mask.cuda(), token_type_ids.cuda(), labels.cuda()\n",
    "        if scalar is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    labels=labels\n",
    "                )\n",
    "        else:\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=labels\n",
    "            )\n",
    "        \n",
    "        loss, logits = outputs[:2]\n",
    "        preds += logits.cpu().detach().numpy().tolist()\n",
    "    oof[val_index] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Local CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "js2Li0srR1Cq",
    "outputId": "bd44fd20-ccf3-4e42-eb81-677648c73105"
   },
   "outputs": [],
   "source": [
    "# 得到交叉验证结果\n",
    "from sklearn.metrics import mean_squared_error\n",
    "round(np.sqrt(mean_squared_error(train.target.values, oof)), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
