{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022141,
     "end_time": "2021-07-05T10:50:41.051319",
     "exception": false,
     "start_time": "2021-07-05T10:50:41.029178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "https://uku28motab.feishu.cn/docs/doccnUDbEhudHm2V440lcY87B1c    \n",
    "This is kernel is almost the same as [Lightweight Roberta solution in PyTorch](https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch), but instead of \"roberta-base\", it starts from [Maunish's pre-trained model](https://www.kaggle.com/maunish/clrp-roberta-base).\n",
    "\n",
    "Acknowledgments: some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:41.097288Z",
     "iopub.status.busy": "2021-07-05T10:50:41.096432Z",
     "iopub.status.idle": "2021-07-05T10:50:49.870855Z",
     "shell.execute_reply": "2021-07-05T10:50:49.870153Z"
    },
    "papermill": {
     "duration": 8.804789,
     "end_time": "2021-07-05T10:50:49.871039",
     "exception": false,
     "start_time": "2021-07-05T10:50:41.066250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入相关库文件\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:49.956708Z",
     "iopub.status.busy": "2021-07-05T10:50:49.955471Z",
     "iopub.status.idle": "2021-07-05T10:50:49.958306Z",
     "shell.execute_reply": "2021-07-05T10:50:49.958949Z"
    },
    "papermill": {
     "duration": 0.072413,
     "end_time": "2021-07-05T10:50:49.959102",
     "exception": false,
     "start_time": "2021-07-05T10:50:49.886689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 参数\n",
    "NUM_FOLDS = 10\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 248\n",
    "EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
    "ROBERTA_PATH = \"../input/clrp-roberta-base/clrp_roberta_base\"\n",
    "TOKENIZER_PATH = \"../input/clrp-roberta-base/clrp_roberta_base\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:49.995963Z",
     "iopub.status.busy": "2021-07-05T10:50:49.994872Z",
     "iopub.status.idle": "2021-07-05T10:50:49.997765Z",
     "shell.execute_reply": "2021-07-05T10:50:49.998291Z"
    },
    "papermill": {
     "duration": 0.024158,
     "end_time": "2021-07-05T10:50:49.998495",
     "exception": false,
     "start_time": "2021-07-05T10:50:49.974337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设定随机种子\n",
    "def set_random_seed(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:50.036773Z",
     "iopub.status.busy": "2021-07-05T10:50:50.036098Z",
     "iopub.status.idle": "2021-07-05T10:50:50.158475Z",
     "shell.execute_reply": "2021-07-05T10:50:50.157887Z"
    },
    "papermill": {
     "duration": 0.145162,
     "end_time": "2021-07-05T10:50:50.158621",
     "exception": false,
     "start_time": "2021-07-05T10:50:50.013459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据，标签的路径\n",
    "train_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/train.csv\")\n",
    "\n",
    "# 如果训练中有不完整的条目存在，请删除。\n",
    "train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n",
    "              inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n",
    "submission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:50.194736Z",
     "iopub.status.busy": "2021-07-05T10:50:50.194000Z",
     "iopub.status.idle": "2021-07-05T10:50:50.426581Z",
     "shell.execute_reply": "2021-07-05T10:50:50.426027Z"
    },
    "papermill": {
     "duration": 0.252252,
     "end_time": "2021-07-05T10:50:50.426728",
     "exception": false,
     "start_time": "2021-07-05T10:50:50.174476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 从指定的路径读取分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015119,
     "end_time": "2021-07-05T10:50:50.457731",
     "exception": false,
     "start_time": "2021-07-05T10:50:50.442612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:50.498560Z",
     "iopub.status.busy": "2021-07-05T10:50:50.497223Z",
     "iopub.status.idle": "2021-07-05T10:50:50.500162Z",
     "shell.execute_reply": "2021-07-05T10:50:50.500715Z"
    },
    "papermill": {
     "duration": 0.027304,
     "end_time": "2021-07-05T10:50:50.500882",
     "exception": false,
     "start_time": "2021-07-05T10:50:50.473578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据整理（便于输入模型）\n",
    "class LitDataset(Dataset):\n",
    "    def __init__(self, df, inference_only=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.df = df        \n",
    "        self.inference_only = inference_only\n",
    "        self.text = df.excerpt.tolist()\n",
    "        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n",
    "        # \n",
    "        if not self.inference_only:\n",
    "            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n",
    "    \n",
    "        self.encoded = tokenizer.batch_encode_plus(\n",
    "            self.text,\n",
    "            padding = 'max_length',            \n",
    "            max_length = MAX_LEN,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True\n",
    "        )        \n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
    "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
    "        \n",
    "        if self.inference_only:\n",
    "            return (input_ids, attention_mask)            \n",
    "        else:\n",
    "            target = self.target[index]\n",
    "            return (input_ids, attention_mask, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015384,
     "end_time": "2021-07-05T10:50:50.531629",
     "exception": false,
     "start_time": "2021-07-05T10:50:50.516245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:50.571359Z",
     "iopub.status.busy": "2021-07-05T10:50:50.570443Z",
     "iopub.status.idle": "2021-07-05T10:50:50.573491Z",
     "shell.execute_reply": "2021-07-05T10:50:50.574066Z"
    },
    "papermill": {
     "duration": 0.027468,
     "end_time": "2021-07-05T10:50:50.574224",
     "exception": false,
     "start_time": "2021-07-05T10:50:50.546756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型\n",
    "class LitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n",
    "        config.update({\"output_hidden_states\":True, \n",
    "                       \"hidden_dropout_prob\": 0.0,\n",
    "                       \"layer_norm_eps\": 1e-7})                       \n",
    "        \n",
    "        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "            \n",
    "        self.attention = nn.Sequential(            \n",
    "            nn.Linear(768, 512),            \n",
    "            nn.Tanh(),                       \n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )        \n",
    "\n",
    "        self.regressor = nn.Sequential(                        \n",
    "            nn.Linear(768, 1)                        \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        roberta_output = self.roberta(input_ids=input_ids,\n",
    "                                      attention_mask=attention_mask)        \n",
    "\n",
    "        # There are a total of 13 layers of hidden states.\n",
    "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "        # We take the hidden states from the last Roberta layer.\n",
    "        last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "\n",
    "        # The number of cells is MAX_LEN.\n",
    "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "        # In order to condense hidden states of all cells to a context vector,\n",
    "        # we compute a weighted average of the hidden states of all cells.\n",
    "        # We compute the weight of each cell, using the attention neural network.\n",
    "        weights = self.attention(last_layer_hidden_states)\n",
    "                \n",
    "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "        # Now we compute context_vector as the weighted average.\n",
    "        # context_vector.shape is BATCH_SIZE x 768\n",
    "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
    "        \n",
    "        # Now we reduce the context vector to the prediction score.\n",
    "        return self.regressor(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:50.612609Z",
     "iopub.status.busy": "2021-07-05T10:50:50.611622Z",
     "iopub.status.idle": "2021-07-05T10:50:50.615278Z",
     "shell.execute_reply": "2021-07-05T10:50:50.614730Z"
    },
    "papermill": {
     "duration": 0.025817,
     "end_time": "2021-07-05T10:50:50.615419",
     "exception": false,
     "start_time": "2021-07-05T10:50:50.589602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_mse(model, data_loader):\n",
    "    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()            \n",
    "    mse_sum = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)                        \n",
    "            target = target.to(DEVICE)           \n",
    "            \n",
    "            pred = model(input_ids, attention_mask)                       \n",
    "\n",
    "            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item()\n",
    "                \n",
    "\n",
    "    return mse_sum / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:50.656547Z",
     "iopub.status.busy": "2021-07-05T10:50:50.655392Z",
     "iopub.status.idle": "2021-07-05T10:50:50.660486Z",
     "shell.execute_reply": "2021-07-05T10:50:50.661845Z"
    },
    "papermill": {
     "duration": 0.030779,
     "end_time": "2021-07-05T10:50:50.662083",
     "exception": false,
     "start_time": "2021-07-05T10:50:50.631304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    result = np.zeros(len(data_loader.dataset))    \n",
    "    index = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "                        \n",
    "            pred = model(input_ids, attention_mask)                        \n",
    "\n",
    "            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
    "            index += pred.shape[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:50.712294Z",
     "iopub.status.busy": "2021-07-05T10:50:50.711300Z",
     "iopub.status.idle": "2021-07-05T10:50:50.714542Z",
     "shell.execute_reply": "2021-07-05T10:50:50.713919Z"
    },
    "papermill": {
     "duration": 0.029895,
     "end_time": "2021-07-05T10:50:50.714686",
     "exception": false,
     "start_time": "2021-07-05T10:50:50.684791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, model_path, train_loader, val_loader,\n",
    "          optimizer, scheduler=None, num_epochs=NUM_EPOCHS):    \n",
    "    best_val_rmse = None\n",
    "    best_epoch = 0\n",
    "    step = 0\n",
    "    last_eval_step = 0\n",
    "    eval_period = EVAL_SCHEDULE[0][1]    \n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):                           \n",
    "        val_rmse = None         \n",
    "\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)            \n",
    "            target = target.to(DEVICE)                        \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "            pred = model(input_ids, attention_mask)\n",
    "                                                        \n",
    "            mse = nn.MSELoss(reduction=\"mean\")(pred.flatten(), target)\n",
    "                        \n",
    "            mse.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            \n",
    "            if step >= last_eval_step + eval_period:\n",
    "                # Evaluate the model on val_loader.\n",
    "                elapsed_seconds = time.time() - start\n",
    "                num_steps = step - last_eval_step\n",
    "                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n",
    "                last_eval_step = step\n",
    "                \n",
    "                val_rmse = math.sqrt(eval_mse(model, val_loader))                            \n",
    "\n",
    "                print(f\"Epoch: {epoch} batch_num: {batch_num}\", \n",
    "                      f\"val_rmse: {val_rmse:0.4}\")\n",
    "\n",
    "                for rmse, period in EVAL_SCHEDULE:\n",
    "                    if val_rmse >= rmse:\n",
    "                        eval_period = period\n",
    "                        break                               \n",
    "                \n",
    "                if not best_val_rmse or val_rmse < best_val_rmse:                    \n",
    "                    best_val_rmse = val_rmse\n",
    "                    best_epoch = epoch\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n",
    "                else:       \n",
    "                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\",\n",
    "                          f\"(from epoch {best_epoch})\")                                    \n",
    "                    \n",
    "                start = time.time()\n",
    "                                            \n",
    "            step += 1\n",
    "                        \n",
    "    \n",
    "    return best_val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:50.754266Z",
     "iopub.status.busy": "2021-07-05T10:50:50.753380Z",
     "iopub.status.idle": "2021-07-05T10:50:50.756920Z",
     "shell.execute_reply": "2021-07-05T10:50:50.756347Z"
    },
    "papermill": {
     "duration": 0.026963,
     "end_time": "2021-07-05T10:50:50.757052",
     "exception": false,
     "start_time": "2021-07-05T10:50:50.730089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_optimizer(model):\n",
    "    named_parameters = list(model.named_parameters())    \n",
    "    \n",
    "    roberta_parameters = named_parameters[:197]    \n",
    "    attention_parameters = named_parameters[199:203]\n",
    "    regressor_parameters = named_parameters[203:]\n",
    "        \n",
    "    attention_group = [params for (name, params) in attention_parameters]\n",
    "    regressor_group = [params for (name, params) in regressor_parameters]\n",
    "\n",
    "    parameters = []\n",
    "    parameters.append({\"params\": attention_group})\n",
    "    parameters.append({\"params\": regressor_group})\n",
    "\n",
    "    for layer_num, (name, params) in enumerate(roberta_parameters):\n",
    "        weight_decay = 0.0 if \"bias\" in name else 0.01\n",
    "\n",
    "        lr = 3e-5\n",
    "\n",
    "        if layer_num >= 69:        \n",
    "            lr = 5e-5\n",
    "\n",
    "        if layer_num >= 133:\n",
    "            lr = 1e-4\n",
    "\n",
    "        parameters.append({\"params\": params,\n",
    "                           \"weight_decay\": weight_decay,\n",
    "                           \"lr\": lr})\n",
    "\n",
    "    return AdamW(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T10:50:50.966296Z",
     "iopub.status.busy": "2021-07-05T10:50:50.965189Z",
     "iopub.status.idle": "2021-07-05T12:24:25.864611Z",
     "shell.execute_reply": "2021-07-05T12:24:25.865112Z"
    },
    "papermill": {
     "duration": 5615.092367,
     "end_time": "2021-07-05T12:24:25.865395",
     "exception": false,
     "start_time": "2021-07-05T10:50:50.773028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 14.0 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9813\n",
      "New best_val_rmse: 0.9813\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7596\n",
      "New best_val_rmse: 0.7596\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.612\n",
      "New best_val_rmse: 0.612\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.554\n",
      "New best_val_rmse: 0.554\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 1 val_rmse: 0.5655\n",
      "Still best_val_rmse: 0.554 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 17 val_rmse: 0.5432\n",
      "New best_val_rmse: 0.5432\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 33 val_rmse: 0.5311\n",
      "New best_val_rmse: 0.5311\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 49 val_rmse: 0.5438\n",
      "Still best_val_rmse: 0.5311 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 65 val_rmse: 0.6269\n",
      "Still best_val_rmse: 0.5311 (from epoch 1)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 2 batch_num: 2 val_rmse: 0.5536\n",
      "Still best_val_rmse: 0.5311 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 18 val_rmse: 0.5134\n",
      "New best_val_rmse: 0.5134\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 34 val_rmse: 0.5149\n",
      "Still best_val_rmse: 0.5134 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 50 val_rmse: 0.5212\n",
      "Still best_val_rmse: 0.5134 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 66 val_rmse: 0.5129\n",
      "New best_val_rmse: 0.5129\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 3 batch_num: 3 val_rmse: 0.5024\n",
      "New best_val_rmse: 0.5024\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 3 batch_num: 19 val_rmse: 0.5109\n",
      "Still best_val_rmse: 0.5024 (from epoch 3)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 3 batch_num: 35 val_rmse: 0.5103\n",
      "Still best_val_rmse: 0.5024 (from epoch 3)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 3 batch_num: 51 val_rmse: 0.507\n",
      "Still best_val_rmse: 0.5024 (from epoch 3)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 3 batch_num: 67 val_rmse: 0.5065\n",
      "Still best_val_rmse: 0.5024 (from epoch 3)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 4 batch_num: 4 val_rmse: 0.5078\n",
      "Still best_val_rmse: 0.5024 (from epoch 3)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 4 batch_num: 20 val_rmse: 0.5088\n",
      "Still best_val_rmse: 0.5024 (from epoch 3)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 4 batch_num: 36 val_rmse: 0.5092\n",
      "Still best_val_rmse: 0.5024 (from epoch 3)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 4 batch_num: 52 val_rmse: 0.5079\n",
      "Still best_val_rmse: 0.5024 (from epoch 3)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 4 batch_num: 68 val_rmse: 0.5084\n",
      "Still best_val_rmse: 0.5024 (from epoch 3)\n",
      "\n",
      "Performance estimates:\n",
      "[0.502424615641487]\n",
      "Mean: 0.502424615641487\n",
      "\n",
      "Fold 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8957\n",
      "New best_val_rmse: 0.8957\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.6906\n",
      "New best_val_rmse: 0.6906\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.5685\n",
      "New best_val_rmse: 0.5685\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.505\n",
      "New best_val_rmse: 0.505\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 1 batch_num: 1 val_rmse: 0.5197\n",
      "Still best_val_rmse: 0.505 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 17 val_rmse: 0.5742\n",
      "Still best_val_rmse: 0.505 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 33 val_rmse: 0.5549\n",
      "Still best_val_rmse: 0.505 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 49 val_rmse: 0.5062\n",
      "Still best_val_rmse: 0.505 (from epoch 0)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 65 val_rmse: 0.475\n",
      "New best_val_rmse: 0.475\n",
      "\n",
      "2 steps took 1.54 seconds\n",
      "Epoch: 1 batch_num: 67 val_rmse: 0.4794\n",
      "Still best_val_rmse: 0.475 (from epoch 1)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 1 batch_num: 69 val_rmse: 0.4756\n",
      "Still best_val_rmse: 0.475 (from epoch 1)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 1 batch_num: 71 val_rmse: 0.4909\n",
      "Still best_val_rmse: 0.475 (from epoch 1)\n",
      "\n",
      "8 steps took 6.24 seconds\n",
      "Epoch: 2 batch_num: 0 val_rmse: 0.4975\n",
      "Still best_val_rmse: 0.475 (from epoch 1)\n",
      "\n",
      "8 steps took 6.09 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.55\n",
      "Still best_val_rmse: 0.475 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4782\n",
      "Still best_val_rmse: 0.475 (from epoch 1)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 26 val_rmse: 0.5023\n",
      "Still best_val_rmse: 0.475 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 42 val_rmse: 0.5305\n",
      "Still best_val_rmse: 0.475 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 58 val_rmse: 0.4758\n",
      "Still best_val_rmse: 0.475 (from epoch 1)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4729\n",
      "New best_val_rmse: 0.4729\n",
      "\n",
      "2 steps took 1.6 seconds\n",
      "Epoch: 2 batch_num: 62 val_rmse: 0.4923\n",
      "Still best_val_rmse: 0.4729 (from epoch 2)\n",
      "\n",
      "8 steps took 6.06 seconds\n",
      "Epoch: 2 batch_num: 70 val_rmse: 0.5136\n",
      "Still best_val_rmse: 0.4729 (from epoch 2)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 3 batch_num: 7 val_rmse: 0.469\n",
      "New best_val_rmse: 0.469\n",
      "\n",
      "1 steps took 0.789 seconds\n",
      "Epoch: 3 batch_num: 8 val_rmse: 0.4679\n",
      "New best_val_rmse: 0.4679\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 9 val_rmse: 0.4655\n",
      "New best_val_rmse: 0.4655\n",
      "\n",
      "1 steps took 0.805 seconds\n",
      "Epoch: 3 batch_num: 10 val_rmse: 0.4637\n",
      "New best_val_rmse: 0.4637\n",
      "\n",
      "1 steps took 0.776 seconds\n",
      "Epoch: 3 batch_num: 11 val_rmse: 0.4637\n",
      "New best_val_rmse: 0.4637\n",
      "\n",
      "1 steps took 0.787 seconds\n",
      "Epoch: 3 batch_num: 12 val_rmse: 0.4638\n",
      "Still best_val_rmse: 0.4637 (from epoch 3)\n",
      "\n",
      "1 steps took 0.779 seconds\n",
      "Epoch: 3 batch_num: 13 val_rmse: 0.4629\n",
      "New best_val_rmse: 0.4629\n",
      "\n",
      "1 steps took 0.794 seconds\n",
      "Epoch: 3 batch_num: 14 val_rmse: 0.4645\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 15 val_rmse: 0.4697\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.796 seconds\n",
      "Epoch: 3 batch_num: 16 val_rmse: 0.4789\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 18 val_rmse: 0.493\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "8 steps took 6.07 seconds\n",
      "Epoch: 3 batch_num: 26 val_rmse: 0.4896\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 3 batch_num: 30 val_rmse: 0.4726\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 3 batch_num: 32 val_rmse: 0.4645\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 33 val_rmse: 0.465\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 34 val_rmse: 0.4654\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 35 val_rmse: 0.464\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 3 batch_num: 36 val_rmse: 0.4668\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 37 val_rmse: 0.475\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 39 val_rmse: 0.4934\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 3 batch_num: 47 val_rmse: 0.4816\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "4 steps took 3.06 seconds\n",
      "Epoch: 3 batch_num: 51 val_rmse: 0.4792\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 53 val_rmse: 0.4744\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 55 val_rmse: 0.4753\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.57 seconds\n",
      "Epoch: 3 batch_num: 57 val_rmse: 0.4778\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 59 val_rmse: 0.4795\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 61 val_rmse: 0.4786\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 3 batch_num: 63 val_rmse: 0.4783\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 3 batch_num: 65 val_rmse: 0.4749\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 67 val_rmse: 0.4699\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 68 val_rmse: 0.4685\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 3 batch_num: 69 val_rmse: 0.4677\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 70 val_rmse: 0.4685\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.83 seconds\n",
      "Epoch: 3 batch_num: 71 val_rmse: 0.4694\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 3 batch_num: 72 val_rmse: 0.4721\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 74 val_rmse: 0.4773\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 3 batch_num: 76 val_rmse: 0.476\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 78 val_rmse: 0.4761\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.68 seconds\n",
      "Epoch: 4 batch_num: 1 val_rmse: 0.4757\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.55 seconds\n",
      "Epoch: 4 batch_num: 3 val_rmse: 0.4747\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 5 val_rmse: 0.4743\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 7 val_rmse: 0.4733\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.62 seconds\n",
      "Epoch: 4 batch_num: 9 val_rmse: 0.4744\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 11 val_rmse: 0.4761\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 13 val_rmse: 0.4769\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 15 val_rmse: 0.4761\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 17 val_rmse: 0.4759\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 19 val_rmse: 0.4734\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 21 val_rmse: 0.4694\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 4 batch_num: 22 val_rmse: 0.4684\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 23 val_rmse: 0.4676\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.805 seconds\n",
      "Epoch: 4 batch_num: 24 val_rmse: 0.4675\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 25 val_rmse: 0.4676\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 26 val_rmse: 0.468\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.777 seconds\n",
      "Epoch: 4 batch_num: 27 val_rmse: 0.4687\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 28 val_rmse: 0.4694\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 29 val_rmse: 0.4698\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 30 val_rmse: 0.4702\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 32 val_rmse: 0.4714\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 34 val_rmse: 0.4734\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 36 val_rmse: 0.4757\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 38 val_rmse: 0.4767\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.4771\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 42 val_rmse: 0.4768\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 44 val_rmse: 0.4764\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 4 batch_num: 46 val_rmse: 0.4757\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.54 seconds\n",
      "Epoch: 4 batch_num: 48 val_rmse: 0.4751\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 50 val_rmse: 0.4747\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 52 val_rmse: 0.4752\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.65 seconds\n",
      "Epoch: 4 batch_num: 54 val_rmse: 0.4757\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 56 val_rmse: 0.4759\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 58 val_rmse: 0.476\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 60 val_rmse: 0.476\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 62 val_rmse: 0.476\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 64 val_rmse: 0.476\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 66 val_rmse: 0.476\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 68 val_rmse: 0.476\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 4 batch_num: 70 val_rmse: 0.4759\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 4 batch_num: 72 val_rmse: 0.4759\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 74 val_rmse: 0.4759\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 76 val_rmse: 0.4759\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 78 val_rmse: 0.4759\n",
      "Still best_val_rmse: 0.4629 (from epoch 3)\n",
      "\n",
      "Performance estimates:\n",
      "[0.502424615641487, 0.4629009152961681]\n",
      "Mean: 0.4826627654688276\n",
      "\n",
      "Fold 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9205\n",
      "New best_val_rmse: 0.9205\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.6926\n",
      "New best_val_rmse: 0.6926\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.5766\n",
      "New best_val_rmse: 0.5766\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.5267\n",
      "New best_val_rmse: 0.5267\n",
      "\n",
      "16 steps took 12.6 seconds\n",
      "Epoch: 1 batch_num: 1 val_rmse: 0.5577\n",
      "Still best_val_rmse: 0.5267 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 17 val_rmse: 0.6186\n",
      "Still best_val_rmse: 0.5267 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 33 val_rmse: 0.5156\n",
      "New best_val_rmse: 0.5156\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 49 val_rmse: 0.5101\n",
      "New best_val_rmse: 0.5101\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 65 val_rmse: 0.4672\n",
      "New best_val_rmse: 0.4672\n",
      "\n",
      "1 steps took 0.787 seconds\n",
      "Epoch: 1 batch_num: 66 val_rmse: 0.4747\n",
      "Still best_val_rmse: 0.4672 (from epoch 1)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 1 batch_num: 68 val_rmse: 0.4668\n",
      "New best_val_rmse: 0.4668\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 1 batch_num: 69 val_rmse: 0.467\n",
      "Still best_val_rmse: 0.4668 (from epoch 1)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 1 batch_num: 70 val_rmse: 0.4698\n",
      "Still best_val_rmse: 0.4668 (from epoch 1)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 1 batch_num: 71 val_rmse: 0.4675\n",
      "Still best_val_rmse: 0.4668 (from epoch 1)\n",
      "\n",
      "1 steps took 0.805 seconds\n",
      "Epoch: 1 batch_num: 72 val_rmse: 0.491\n",
      "Still best_val_rmse: 0.4668 (from epoch 1)\n",
      "\n",
      "8 steps took 6.2 seconds\n",
      "Epoch: 2 batch_num: 1 val_rmse: 0.4924\n",
      "Still best_val_rmse: 0.4668 (from epoch 1)\n",
      "\n",
      "8 steps took 6.29 seconds\n",
      "Epoch: 2 batch_num: 9 val_rmse: 0.4667\n",
      "New best_val_rmse: 0.4667\n",
      "\n",
      "1 steps took 0.806 seconds\n",
      "Epoch: 2 batch_num: 10 val_rmse: 0.4761\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 2 batch_num: 12 val_rmse: 0.4801\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 16 val_rmse: 0.4905\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4801\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "4 steps took 3.19 seconds\n",
      "Epoch: 2 batch_num: 28 val_rmse: 0.478\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 30 val_rmse: 0.4679\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 2 batch_num: 31 val_rmse: 0.4766\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 33 val_rmse: 0.472\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 35 val_rmse: 0.4693\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.4697\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "1 steps took 0.777 seconds\n",
      "Epoch: 2 batch_num: 37 val_rmse: 0.4694\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 38 val_rmse: 0.4721\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4706\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "2 steps took 1.6 seconds\n",
      "Epoch: 2 batch_num: 42 val_rmse: 0.4984\n",
      "Still best_val_rmse: 0.4667 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 50 val_rmse: 0.4567\n",
      "New best_val_rmse: 0.4567\n",
      "\n",
      "1 steps took 0.768 seconds\n",
      "Epoch: 2 batch_num: 51 val_rmse: 0.4576\n",
      "Still best_val_rmse: 0.4567 (from epoch 2)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4587\n",
      "Still best_val_rmse: 0.4567 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 2 batch_num: 53 val_rmse: 0.456\n",
      "New best_val_rmse: 0.456\n",
      "\n",
      "1 steps took 0.766 seconds\n",
      "Epoch: 2 batch_num: 54 val_rmse: 0.4584\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 2 batch_num: 55 val_rmse: 0.4604\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4564\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.794 seconds\n",
      "Epoch: 2 batch_num: 57 val_rmse: 0.4597\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 2 batch_num: 58 val_rmse: 0.4607\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 2 batch_num: 59 val_rmse: 0.4615\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.46\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 2 batch_num: 61 val_rmse: 0.458\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 2 batch_num: 62 val_rmse: 0.4575\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 2 batch_num: 63 val_rmse: 0.4594\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4635\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 2 batch_num: 65 val_rmse: 0.4682\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.762 seconds\n",
      "Epoch: 2 batch_num: 66 val_rmse: 0.4745\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4936\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "8 steps took 6.03 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4936\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "8 steps took 6.2 seconds\n",
      "Epoch: 3 batch_num: 5 val_rmse: 0.4803\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "4 steps took 3.05 seconds\n",
      "Epoch: 3 batch_num: 9 val_rmse: 0.4601\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 10 val_rmse: 0.4612\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 11 val_rmse: 0.4608\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 3 batch_num: 12 val_rmse: 0.459\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.767 seconds\n",
      "Epoch: 3 batch_num: 13 val_rmse: 0.4609\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 14 val_rmse: 0.4681\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 15 val_rmse: 0.4732\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 3 batch_num: 17 val_rmse: 0.4769\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 19 val_rmse: 0.4693\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 20 val_rmse: 0.4672\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 3 batch_num: 21 val_rmse: 0.4634\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 22 val_rmse: 0.4612\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 23 val_rmse: 0.4626\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 24 val_rmse: 0.4646\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.781 seconds\n",
      "Epoch: 3 batch_num: 25 val_rmse: 0.466\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 26 val_rmse: 0.4688\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 3 batch_num: 27 val_rmse: 0.4677\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.779 seconds\n",
      "Epoch: 3 batch_num: 28 val_rmse: 0.4697\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 29 val_rmse: 0.4629\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 30 val_rmse: 0.4589\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 31 val_rmse: 0.4563\n",
      "Still best_val_rmse: 0.456 (from epoch 2)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 32 val_rmse: 0.4558\n",
      "New best_val_rmse: 0.4558\n",
      "\n",
      "1 steps took 0.775 seconds\n",
      "Epoch: 3 batch_num: 33 val_rmse: 0.4558\n",
      "Still best_val_rmse: 0.4558 (from epoch 3)\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 3 batch_num: 34 val_rmse: 0.4566\n",
      "Still best_val_rmse: 0.4558 (from epoch 3)\n",
      "\n",
      "1 steps took 0.788 seconds\n",
      "Epoch: 3 batch_num: 35 val_rmse: 0.4583\n",
      "Still best_val_rmse: 0.4558 (from epoch 3)\n",
      "\n",
      "1 steps took 0.762 seconds\n",
      "Epoch: 3 batch_num: 36 val_rmse: 0.4608\n",
      "Still best_val_rmse: 0.4558 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 37 val_rmse: 0.4623\n",
      "Still best_val_rmse: 0.4558 (from epoch 3)\n",
      "\n",
      "1 steps took 0.77 seconds\n",
      "Epoch: 3 batch_num: 38 val_rmse: 0.4656\n",
      "Still best_val_rmse: 0.4558 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 39 val_rmse: 0.4665\n",
      "Still best_val_rmse: 0.4558 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 40 val_rmse: 0.4625\n",
      "Still best_val_rmse: 0.4558 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 41 val_rmse: 0.4564\n",
      "Still best_val_rmse: 0.4558 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 42 val_rmse: 0.4546\n",
      "New best_val_rmse: 0.4546\n",
      "\n",
      "1 steps took 0.77 seconds\n",
      "Epoch: 3 batch_num: 43 val_rmse: 0.4535\n",
      "New best_val_rmse: 0.4535\n",
      "\n",
      "1 steps took 0.846 seconds\n",
      "Epoch: 3 batch_num: 44 val_rmse: 0.4542\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 45 val_rmse: 0.4551\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 46 val_rmse: 0.4555\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.793 seconds\n",
      "Epoch: 3 batch_num: 47 val_rmse: 0.4576\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.764 seconds\n",
      "Epoch: 3 batch_num: 48 val_rmse: 0.4623\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 49 val_rmse: 0.4706\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "2 steps took 1.54 seconds\n",
      "Epoch: 3 batch_num: 51 val_rmse: 0.4716\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 53 val_rmse: 0.4643\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 54 val_rmse: 0.4591\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 55 val_rmse: 0.4571\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.769 seconds\n",
      "Epoch: 3 batch_num: 56 val_rmse: 0.4569\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 3 batch_num: 57 val_rmse: 0.4571\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 58 val_rmse: 0.456\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 3 batch_num: 59 val_rmse: 0.4565\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 60 val_rmse: 0.4611\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 61 val_rmse: 0.4676\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 62 val_rmse: 0.47\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 3 batch_num: 64 val_rmse: 0.4648\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 65 val_rmse: 0.4603\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 66 val_rmse: 0.4574\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.793 seconds\n",
      "Epoch: 3 batch_num: 67 val_rmse: 0.4559\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 68 val_rmse: 0.4556\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 69 val_rmse: 0.4559\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 70 val_rmse: 0.4561\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 71 val_rmse: 0.4573\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 3 batch_num: 72 val_rmse: 0.4606\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 3 batch_num: 73 val_rmse: 0.4636\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 74 val_rmse: 0.4656\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 3 batch_num: 75 val_rmse: 0.4674\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 3 batch_num: 76 val_rmse: 0.4666\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 77 val_rmse: 0.4641\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 78 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.924 seconds\n",
      "Epoch: 4 batch_num: 0 val_rmse: 0.4587\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.751 seconds\n",
      "Epoch: 4 batch_num: 1 val_rmse: 0.457\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 4 batch_num: 2 val_rmse: 0.4556\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 3 val_rmse: 0.4547\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 4 val_rmse: 0.4543\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 5 val_rmse: 0.4542\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 6 val_rmse: 0.4546\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 7 val_rmse: 0.4549\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 8 val_rmse: 0.4557\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.81 seconds\n",
      "Epoch: 4 batch_num: 9 val_rmse: 0.4566\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 10 val_rmse: 0.4577\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 11 val_rmse: 0.4592\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 12 val_rmse: 0.4611\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 13 val_rmse: 0.4629\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 14 val_rmse: 0.464\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 15 val_rmse: 0.4645\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.767 seconds\n",
      "Epoch: 4 batch_num: 16 val_rmse: 0.4636\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 4 batch_num: 17 val_rmse: 0.4624\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 18 val_rmse: 0.4615\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.762 seconds\n",
      "Epoch: 4 batch_num: 19 val_rmse: 0.4608\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 20 val_rmse: 0.4605\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 21 val_rmse: 0.4597\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 4 batch_num: 22 val_rmse: 0.4591\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.765 seconds\n",
      "Epoch: 4 batch_num: 23 val_rmse: 0.4589\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.75 seconds\n",
      "Epoch: 4 batch_num: 24 val_rmse: 0.4587\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 25 val_rmse: 0.4589\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 4 batch_num: 26 val_rmse: 0.459\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 27 val_rmse: 0.4591\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 28 val_rmse: 0.4594\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 29 val_rmse: 0.4596\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.841 seconds\n",
      "Epoch: 4 batch_num: 30 val_rmse: 0.4601\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 31 val_rmse: 0.4605\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 32 val_rmse: 0.4604\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 33 val_rmse: 0.4599\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 34 val_rmse: 0.4597\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 35 val_rmse: 0.4596\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 4 batch_num: 36 val_rmse: 0.46\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.771 seconds\n",
      "Epoch: 4 batch_num: 37 val_rmse: 0.4605\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 38 val_rmse: 0.4609\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 39 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.4612\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.787 seconds\n",
      "Epoch: 4 batch_num: 41 val_rmse: 0.4611\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 42 val_rmse: 0.4608\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 43 val_rmse: 0.4603\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.769 seconds\n",
      "Epoch: 4 batch_num: 44 val_rmse: 0.4599\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 45 val_rmse: 0.4596\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 46 val_rmse: 0.4594\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 47 val_rmse: 0.4594\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 48 val_rmse: 0.4594\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 49 val_rmse: 0.4594\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 50 val_rmse: 0.4595\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.77 seconds\n",
      "Epoch: 4 batch_num: 51 val_rmse: 0.4596\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 52 val_rmse: 0.4599\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 53 val_rmse: 0.4602\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 54 val_rmse: 0.4604\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 4 batch_num: 55 val_rmse: 0.4606\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 56 val_rmse: 0.4608\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 57 val_rmse: 0.4609\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.766 seconds\n",
      "Epoch: 4 batch_num: 58 val_rmse: 0.461\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 59 val_rmse: 0.461\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 4 batch_num: 60 val_rmse: 0.4611\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.762 seconds\n",
      "Epoch: 4 batch_num: 61 val_rmse: 0.4612\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.802 seconds\n",
      "Epoch: 4 batch_num: 62 val_rmse: 0.4612\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 63 val_rmse: 0.4612\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 64 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.778 seconds\n",
      "Epoch: 4 batch_num: 65 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 66 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 67 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 68 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 69 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 4 batch_num: 70 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 71 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.773 seconds\n",
      "Epoch: 4 batch_num: 72 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 4 batch_num: 73 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 4 batch_num: 74 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 75 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 76 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 77 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 78 val_rmse: 0.4613\n",
      "Still best_val_rmse: 0.4535 (from epoch 3)\n",
      "\n",
      "Performance estimates:\n",
      "[0.502424615641487, 0.4629009152961681, 0.4534524158034372]\n",
      "Mean: 0.4729259822470308\n",
      "\n",
      "Fold 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9673\n",
      "New best_val_rmse: 0.9673\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7109\n",
      "New best_val_rmse: 0.7109\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6601\n",
      "New best_val_rmse: 0.6601\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.6535\n",
      "New best_val_rmse: 0.6535\n",
      "\n",
      "16 steps took 12.4 seconds\n",
      "Epoch: 1 batch_num: 1 val_rmse: 0.5276\n",
      "New best_val_rmse: 0.5276\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 17 val_rmse: 0.512\n",
      "New best_val_rmse: 0.512\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 33 val_rmse: 0.5373\n",
      "Still best_val_rmse: 0.512 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 49 val_rmse: 0.6822\n",
      "Still best_val_rmse: 0.512 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 65 val_rmse: 0.5029\n",
      "New best_val_rmse: 0.5029\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 2 batch_num: 2 val_rmse: 0.5088\n",
      "Still best_val_rmse: 0.5029 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 18 val_rmse: 0.476\n",
      "New best_val_rmse: 0.476\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.4808\n",
      "Still best_val_rmse: 0.476 (from epoch 2)\n",
      "\n",
      "4 steps took 3.09 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4699\n",
      "New best_val_rmse: 0.4699\n",
      "\n",
      "1 steps took 0.78 seconds\n",
      "Epoch: 2 batch_num: 25 val_rmse: 0.4651\n",
      "New best_val_rmse: 0.4651\n",
      "\n",
      "1 steps took 0.805 seconds\n",
      "Epoch: 2 batch_num: 26 val_rmse: 0.4649\n",
      "New best_val_rmse: 0.4649\n",
      "\n",
      "1 steps took 0.766 seconds\n",
      "Epoch: 2 batch_num: 27 val_rmse: 0.4656\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.785 seconds\n",
      "Epoch: 2 batch_num: 28 val_rmse: 0.466\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.766 seconds\n",
      "Epoch: 2 batch_num: 29 val_rmse: 0.4674\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 30 val_rmse: 0.471\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.475\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.54 seconds\n",
      "Epoch: 2 batch_num: 34 val_rmse: 0.4832\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 38 val_rmse: 0.4844\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "4 steps took 3.06 seconds\n",
      "Epoch: 2 batch_num: 42 val_rmse: 0.4782\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4749\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 2 batch_num: 46 val_rmse: 0.4747\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.56 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4888\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.4683\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 2 batch_num: 53 val_rmse: 0.4682\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 2 batch_num: 54 val_rmse: 0.4686\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 2 batch_num: 55 val_rmse: 0.4713\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 57 val_rmse: 0.4887\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 61 val_rmse: 0.4693\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 2 batch_num: 62 val_rmse: 0.4704\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.4719\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 66 val_rmse: 0.4759\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 68 val_rmse: 0.4837\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "4 steps took 3.07 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4845\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4819\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "4 steps took 3.34 seconds\n",
      "Epoch: 3 batch_num: 1 val_rmse: 0.491\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "8 steps took 6.11 seconds\n",
      "Epoch: 3 batch_num: 9 val_rmse: 0.4739\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 11 val_rmse: 0.469\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.751 seconds\n",
      "Epoch: 3 batch_num: 12 val_rmse: 0.4789\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 14 val_rmse: 0.5156\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 3 batch_num: 30 val_rmse: 0.4765\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 3 batch_num: 32 val_rmse: 0.4738\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 34 val_rmse: 0.495\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 3 batch_num: 42 val_rmse: 0.475\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.56 seconds\n",
      "Epoch: 3 batch_num: 44 val_rmse: 0.4733\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 3 batch_num: 46 val_rmse: 0.4778\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 3 batch_num: 48 val_rmse: 0.4897\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 3 batch_num: 52 val_rmse: 0.4786\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.55 seconds\n",
      "Epoch: 3 batch_num: 54 val_rmse: 0.4828\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 3 batch_num: 58 val_rmse: 0.474\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 60 val_rmse: 0.4906\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "8 steps took 6.07 seconds\n",
      "Epoch: 3 batch_num: 68 val_rmse: 0.4745\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 70 val_rmse: 0.4745\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 72 val_rmse: 0.4721\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 74 val_rmse: 0.4728\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 3 batch_num: 76 val_rmse: 0.4759\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.54 seconds\n",
      "Epoch: 3 batch_num: 78 val_rmse: 0.4797\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.67 seconds\n",
      "Epoch: 4 batch_num: 1 val_rmse: 0.4815\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 5 val_rmse: 0.4706\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 7 val_rmse: 0.4688\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 4 batch_num: 8 val_rmse: 0.4685\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 9 val_rmse: 0.4684\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 10 val_rmse: 0.4683\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.803 seconds\n",
      "Epoch: 4 batch_num: 11 val_rmse: 0.4683\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 12 val_rmse: 0.4683\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 13 val_rmse: 0.4684\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 14 val_rmse: 0.4688\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 15 val_rmse: 0.4696\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 16 val_rmse: 0.471\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 4 batch_num: 18 val_rmse: 0.4734\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 20 val_rmse: 0.4754\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 22 val_rmse: 0.4761\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 24 val_rmse: 0.4749\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 4 batch_num: 26 val_rmse: 0.4751\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 28 val_rmse: 0.4736\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 30 val_rmse: 0.4714\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 32 val_rmse: 0.4707\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 34 val_rmse: 0.4704\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 36 val_rmse: 0.4704\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 38 val_rmse: 0.4706\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.4712\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.55 seconds\n",
      "Epoch: 4 batch_num: 42 val_rmse: 0.4715\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 44 val_rmse: 0.4721\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 4 batch_num: 46 val_rmse: 0.4724\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 48 val_rmse: 0.4727\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 50 val_rmse: 0.473\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 52 val_rmse: 0.4732\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 54 val_rmse: 0.4735\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 56 val_rmse: 0.4737\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 4 batch_num: 58 val_rmse: 0.4738\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 60 val_rmse: 0.4738\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 62 val_rmse: 0.4738\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 64 val_rmse: 0.4739\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 66 val_rmse: 0.474\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 4 batch_num: 68 val_rmse: 0.4741\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 70 val_rmse: 0.4742\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 72 val_rmse: 0.4742\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 4 batch_num: 74 val_rmse: 0.4742\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 4 batch_num: 76 val_rmse: 0.4742\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "2 steps took 1.5 seconds\n",
      "Epoch: 4 batch_num: 78 val_rmse: 0.4742\n",
      "Still best_val_rmse: 0.4649 (from epoch 2)\n",
      "\n",
      "Performance estimates:\n",
      "[0.502424615641487, 0.4629009152961681, 0.4534524158034372, 0.46491112537792356]\n",
      "Mean: 0.470922268029754\n",
      "\n",
      "Fold 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9932\n",
      "New best_val_rmse: 0.9932\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.6753\n",
      "New best_val_rmse: 0.6753\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6982\n",
      "Still best_val_rmse: 0.6753 (from epoch 0)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.561\n",
      "New best_val_rmse: 0.561\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 1 batch_num: 1 val_rmse: 0.5567\n",
      "New best_val_rmse: 0.5567\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 17 val_rmse: 0.5607\n",
      "Still best_val_rmse: 0.5567 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 33 val_rmse: 0.5156\n",
      "New best_val_rmse: 0.5156\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 49 val_rmse: 0.4877\n",
      "New best_val_rmse: 0.4877\n",
      "\n",
      "4 steps took 3.04 seconds\n",
      "Epoch: 1 batch_num: 53 val_rmse: 0.4925\n",
      "Still best_val_rmse: 0.4877 (from epoch 1)\n",
      "\n",
      "8 steps took 6.08 seconds\n",
      "Epoch: 1 batch_num: 61 val_rmse: 0.4851\n",
      "New best_val_rmse: 0.4851\n",
      "\n",
      "4 steps took 3.05 seconds\n",
      "Epoch: 1 batch_num: 65 val_rmse: 0.5085\n",
      "Still best_val_rmse: 0.4851 (from epoch 1)\n",
      "\n",
      "16 steps took 12.4 seconds\n",
      "Epoch: 2 batch_num: 2 val_rmse: 0.5849\n",
      "Still best_val_rmse: 0.4851 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 18 val_rmse: 0.4788\n",
      "New best_val_rmse: 0.4788\n",
      "\n",
      "2 steps took 1.67 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.4824\n",
      "Still best_val_rmse: 0.4788 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 24 val_rmse: 0.4843\n",
      "Still best_val_rmse: 0.4788 (from epoch 2)\n",
      "\n",
      "4 steps took 3.07 seconds\n",
      "Epoch: 2 batch_num: 28 val_rmse: 0.5083\n",
      "Still best_val_rmse: 0.4788 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4879\n",
      "Still best_val_rmse: 0.4788 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.5315\n",
      "Still best_val_rmse: 0.4788 (from epoch 2)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.5195\n",
      "Still best_val_rmse: 0.4788 (from epoch 2)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 3 batch_num: 1 val_rmse: 0.4701\n",
      "New best_val_rmse: 0.4701\n",
      "\n",
      "2 steps took 1.61 seconds\n",
      "Epoch: 3 batch_num: 3 val_rmse: 0.4769\n",
      "Still best_val_rmse: 0.4701 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 5 val_rmse: 0.4909\n",
      "Still best_val_rmse: 0.4701 (from epoch 3)\n",
      "\n",
      "8 steps took 6.09 seconds\n",
      "Epoch: 3 batch_num: 13 val_rmse: 0.4664\n",
      "New best_val_rmse: 0.4664\n",
      "\n",
      "1 steps took 0.779 seconds\n",
      "Epoch: 3 batch_num: 14 val_rmse: 0.4645\n",
      "New best_val_rmse: 0.4645\n",
      "\n",
      "1 steps took 0.819 seconds\n",
      "Epoch: 3 batch_num: 15 val_rmse: 0.4639\n",
      "New best_val_rmse: 0.4639\n",
      "\n",
      "1 steps took 0.771 seconds\n",
      "Epoch: 3 batch_num: 16 val_rmse: 0.4644\n",
      "Still best_val_rmse: 0.4639 (from epoch 3)\n",
      "\n",
      "1 steps took 0.785 seconds\n",
      "Epoch: 3 batch_num: 17 val_rmse: 0.4663\n",
      "Still best_val_rmse: 0.4639 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 18 val_rmse: 0.4716\n",
      "Still best_val_rmse: 0.4639 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 20 val_rmse: 0.4799\n",
      "Still best_val_rmse: 0.4639 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 22 val_rmse: 0.471\n",
      "Still best_val_rmse: 0.4639 (from epoch 3)\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 3 batch_num: 24 val_rmse: 0.4615\n",
      "New best_val_rmse: 0.4615\n",
      "\n",
      "1 steps took 0.767 seconds\n",
      "Epoch: 3 batch_num: 25 val_rmse: 0.4584\n",
      "New best_val_rmse: 0.4584\n",
      "\n",
      "1 steps took 0.836 seconds\n",
      "Epoch: 3 batch_num: 26 val_rmse: 0.4581\n",
      "New best_val_rmse: 0.4581\n",
      "\n",
      "1 steps took 0.775 seconds\n",
      "Epoch: 3 batch_num: 27 val_rmse: 0.4585\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.776 seconds\n",
      "Epoch: 3 batch_num: 28 val_rmse: 0.4594\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 29 val_rmse: 0.4625\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 30 val_rmse: 0.4652\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 31 val_rmse: 0.4663\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.783 seconds\n",
      "Epoch: 3 batch_num: 32 val_rmse: 0.4668\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 33 val_rmse: 0.4662\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 34 val_rmse: 0.4659\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 35 val_rmse: 0.4667\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.781 seconds\n",
      "Epoch: 3 batch_num: 36 val_rmse: 0.4668\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 3 batch_num: 37 val_rmse: 0.4647\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 38 val_rmse: 0.4643\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.779 seconds\n",
      "Epoch: 3 batch_num: 39 val_rmse: 0.4633\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 40 val_rmse: 0.4607\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 41 val_rmse: 0.4591\n",
      "Still best_val_rmse: 0.4581 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 3 batch_num: 42 val_rmse: 0.4569\n",
      "New best_val_rmse: 0.4569\n",
      "\n",
      "1 steps took 0.772 seconds\n",
      "Epoch: 3 batch_num: 43 val_rmse: 0.4565\n",
      "New best_val_rmse: 0.4565\n",
      "\n",
      "1 steps took 0.768 seconds\n",
      "Epoch: 3 batch_num: 44 val_rmse: 0.4582\n",
      "Still best_val_rmse: 0.4565 (from epoch 3)\n",
      "\n",
      "1 steps took 0.801 seconds\n",
      "Epoch: 3 batch_num: 45 val_rmse: 0.4631\n",
      "Still best_val_rmse: 0.4565 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 46 val_rmse: 0.4665\n",
      "Still best_val_rmse: 0.4565 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 47 val_rmse: 0.4697\n",
      "Still best_val_rmse: 0.4565 (from epoch 3)\n",
      "\n",
      "1 steps took 0.787 seconds\n",
      "Epoch: 3 batch_num: 48 val_rmse: 0.469\n",
      "Still best_val_rmse: 0.4565 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 3 batch_num: 49 val_rmse: 0.4659\n",
      "Still best_val_rmse: 0.4565 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 50 val_rmse: 0.4643\n",
      "Still best_val_rmse: 0.4565 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 51 val_rmse: 0.4618\n",
      "Still best_val_rmse: 0.4565 (from epoch 3)\n",
      "\n",
      "1 steps took 0.777 seconds\n",
      "Epoch: 3 batch_num: 52 val_rmse: 0.4583\n",
      "Still best_val_rmse: 0.4565 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 53 val_rmse: 0.4563\n",
      "New best_val_rmse: 0.4563\n",
      "\n",
      "1 steps took 0.782 seconds\n",
      "Epoch: 3 batch_num: 54 val_rmse: 0.4565\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.812 seconds\n",
      "Epoch: 3 batch_num: 55 val_rmse: 0.4573\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 56 val_rmse: 0.4578\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 57 val_rmse: 0.4604\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.769 seconds\n",
      "Epoch: 3 batch_num: 58 val_rmse: 0.4664\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 3 batch_num: 59 val_rmse: 0.4725\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 61 val_rmse: 0.4738\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 63 val_rmse: 0.4718\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 65 val_rmse: 0.471\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 3 batch_num: 67 val_rmse: 0.4665\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.781 seconds\n",
      "Epoch: 3 batch_num: 68 val_rmse: 0.4655\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 69 val_rmse: 0.4659\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 3 batch_num: 70 val_rmse: 0.4665\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.774 seconds\n",
      "Epoch: 3 batch_num: 71 val_rmse: 0.4672\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.775 seconds\n",
      "Epoch: 3 batch_num: 72 val_rmse: 0.467\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 73 val_rmse: 0.4662\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.764 seconds\n",
      "Epoch: 3 batch_num: 74 val_rmse: 0.4662\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 3 batch_num: 75 val_rmse: 0.4658\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.751 seconds\n",
      "Epoch: 3 batch_num: 76 val_rmse: 0.4652\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 3 batch_num: 77 val_rmse: 0.4643\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.783 seconds\n",
      "Epoch: 3 batch_num: 78 val_rmse: 0.4643\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.943 seconds\n",
      "Epoch: 4 batch_num: 0 val_rmse: 0.4643\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 1 val_rmse: 0.4646\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.78 seconds\n",
      "Epoch: 4 batch_num: 2 val_rmse: 0.4655\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 3 val_rmse: 0.4673\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 4 val_rmse: 0.4689\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 5 val_rmse: 0.47\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 6 val_rmse: 0.471\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 4 batch_num: 8 val_rmse: 0.4721\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 4 batch_num: 10 val_rmse: 0.471\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "2 steps took 1.55 seconds\n",
      "Epoch: 4 batch_num: 12 val_rmse: 0.4675\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.769 seconds\n",
      "Epoch: 4 batch_num: 13 val_rmse: 0.466\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 14 val_rmse: 0.4653\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.769 seconds\n",
      "Epoch: 4 batch_num: 15 val_rmse: 0.4648\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 16 val_rmse: 0.465\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 17 val_rmse: 0.4655\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 18 val_rmse: 0.4661\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 4 batch_num: 19 val_rmse: 0.467\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.776 seconds\n",
      "Epoch: 4 batch_num: 20 val_rmse: 0.4685\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 21 val_rmse: 0.4681\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.784 seconds\n",
      "Epoch: 4 batch_num: 22 val_rmse: 0.4674\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 4 batch_num: 23 val_rmse: 0.4667\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 4 batch_num: 24 val_rmse: 0.4664\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.79 seconds\n",
      "Epoch: 4 batch_num: 25 val_rmse: 0.4655\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 26 val_rmse: 0.4646\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.766 seconds\n",
      "Epoch: 4 batch_num: 27 val_rmse: 0.4638\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 28 val_rmse: 0.4629\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 4 batch_num: 29 val_rmse: 0.4623\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 4 batch_num: 30 val_rmse: 0.4623\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 31 val_rmse: 0.4621\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.78 seconds\n",
      "Epoch: 4 batch_num: 32 val_rmse: 0.4623\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 33 val_rmse: 0.4625\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.771 seconds\n",
      "Epoch: 4 batch_num: 34 val_rmse: 0.463\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 35 val_rmse: 0.4634\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 36 val_rmse: 0.4641\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 37 val_rmse: 0.4647\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 38 val_rmse: 0.4652\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 39 val_rmse: 0.4654\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.4655\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.769 seconds\n",
      "Epoch: 4 batch_num: 41 val_rmse: 0.4657\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.779 seconds\n",
      "Epoch: 4 batch_num: 42 val_rmse: 0.4657\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 43 val_rmse: 0.4657\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 44 val_rmse: 0.4657\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 45 val_rmse: 0.4655\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 46 val_rmse: 0.4652\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 47 val_rmse: 0.4648\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.78 seconds\n",
      "Epoch: 4 batch_num: 48 val_rmse: 0.4645\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 4 batch_num: 49 val_rmse: 0.4642\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 50 val_rmse: 0.464\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 51 val_rmse: 0.4639\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.786 seconds\n",
      "Epoch: 4 batch_num: 52 val_rmse: 0.4638\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 53 val_rmse: 0.4636\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 54 val_rmse: 0.4634\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.778 seconds\n",
      "Epoch: 4 batch_num: 55 val_rmse: 0.4633\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.78 seconds\n",
      "Epoch: 4 batch_num: 56 val_rmse: 0.4631\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 57 val_rmse: 0.4629\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 58 val_rmse: 0.4628\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 59 val_rmse: 0.4628\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 60 val_rmse: 0.4628\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 61 val_rmse: 0.4628\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.829 seconds\n",
      "Epoch: 4 batch_num: 62 val_rmse: 0.4628\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 63 val_rmse: 0.4628\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 64 val_rmse: 0.4628\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 65 val_rmse: 0.4629\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 4 batch_num: 66 val_rmse: 0.4629\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 67 val_rmse: 0.463\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 68 val_rmse: 0.463\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.772 seconds\n",
      "Epoch: 4 batch_num: 69 val_rmse: 0.4631\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 70 val_rmse: 0.4631\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 71 val_rmse: 0.4631\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.781 seconds\n",
      "Epoch: 4 batch_num: 72 val_rmse: 0.4631\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 73 val_rmse: 0.4632\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 74 val_rmse: 0.4632\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.749 seconds\n",
      "Epoch: 4 batch_num: 75 val_rmse: 0.4632\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.771 seconds\n",
      "Epoch: 4 batch_num: 76 val_rmse: 0.4632\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.765 seconds\n",
      "Epoch: 4 batch_num: 77 val_rmse: 0.4632\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 78 val_rmse: 0.4632\n",
      "Still best_val_rmse: 0.4563 (from epoch 3)\n",
      "\n",
      "Performance estimates:\n",
      "[0.502424615641487, 0.4629009152961681, 0.4534524158034372, 0.46491112537792356, 0.4563067646445377]\n",
      "Mean: 0.46799916735271074\n",
      "\n",
      "Fold 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 1.009\n",
      "New best_val_rmse: 1.009\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7212\n",
      "New best_val_rmse: 0.7212\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6089\n",
      "New best_val_rmse: 0.6089\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.5598\n",
      "New best_val_rmse: 0.5598\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 1 batch_num: 1 val_rmse: 0.5617\n",
      "Still best_val_rmse: 0.5598 (from epoch 0)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 17 val_rmse: 0.5406\n",
      "New best_val_rmse: 0.5406\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 33 val_rmse: 0.5035\n",
      "New best_val_rmse: 0.5035\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 1 batch_num: 49 val_rmse: 0.5239\n",
      "Still best_val_rmse: 0.5035 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 65 val_rmse: 0.5372\n",
      "Still best_val_rmse: 0.5035 (from epoch 1)\n",
      "\n",
      "16 steps took 12.4 seconds\n",
      "Epoch: 2 batch_num: 2 val_rmse: 0.4965\n",
      "New best_val_rmse: 0.4965\n",
      "\n",
      "8 steps took 6.14 seconds\n",
      "Epoch: 2 batch_num: 10 val_rmse: 0.493\n",
      "New best_val_rmse: 0.493\n",
      "\n",
      "8 steps took 6.08 seconds\n",
      "Epoch: 2 batch_num: 18 val_rmse: 0.5071\n",
      "Still best_val_rmse: 0.493 (from epoch 2)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 34 val_rmse: 0.4929\n",
      "New best_val_rmse: 0.4929\n",
      "\n",
      "8 steps took 6.1 seconds\n",
      "Epoch: 2 batch_num: 42 val_rmse: 0.5002\n",
      "Still best_val_rmse: 0.4929 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 58 val_rmse: 0.4982\n",
      "Still best_val_rmse: 0.4929 (from epoch 2)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 2 batch_num: 66 val_rmse: 0.4981\n",
      "Still best_val_rmse: 0.4929 (from epoch 2)\n",
      "\n",
      "8 steps took 6.06 seconds\n",
      "Epoch: 2 batch_num: 74 val_rmse: 0.4968\n",
      "Still best_val_rmse: 0.4929 (from epoch 2)\n",
      "\n",
      "8 steps took 6.24 seconds\n",
      "Epoch: 3 batch_num: 3 val_rmse: 0.506\n",
      "Still best_val_rmse: 0.4929 (from epoch 2)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 3 batch_num: 19 val_rmse: 0.4922\n",
      "New best_val_rmse: 0.4922\n",
      "\n",
      "8 steps took 6.11 seconds\n",
      "Epoch: 3 batch_num: 27 val_rmse: 0.4958\n",
      "Still best_val_rmse: 0.4922 (from epoch 3)\n",
      "\n",
      "8 steps took 6.11 seconds\n",
      "Epoch: 3 batch_num: 35 val_rmse: 0.4933\n",
      "Still best_val_rmse: 0.4922 (from epoch 3)\n",
      "\n",
      "8 steps took 6.06 seconds\n",
      "Epoch: 3 batch_num: 43 val_rmse: 0.4971\n",
      "Still best_val_rmse: 0.4922 (from epoch 3)\n",
      "\n",
      "8 steps took 6.09 seconds\n",
      "Epoch: 3 batch_num: 51 val_rmse: 0.4838\n",
      "New best_val_rmse: 0.4838\n",
      "\n",
      "4 steps took 3.06 seconds\n",
      "Epoch: 3 batch_num: 55 val_rmse: 0.4844\n",
      "Still best_val_rmse: 0.4838 (from epoch 3)\n",
      "\n",
      "4 steps took 3.03 seconds\n",
      "Epoch: 3 batch_num: 59 val_rmse: 0.4848\n",
      "Still best_val_rmse: 0.4838 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 3 batch_num: 63 val_rmse: 0.4835\n",
      "New best_val_rmse: 0.4835\n",
      "\n",
      "4 steps took 3.07 seconds\n",
      "Epoch: 3 batch_num: 67 val_rmse: 0.484\n",
      "Still best_val_rmse: 0.4835 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 3 batch_num: 71 val_rmse: 0.4833\n",
      "New best_val_rmse: 0.4833\n",
      "\n",
      "4 steps took 3.1 seconds\n",
      "Epoch: 3 batch_num: 75 val_rmse: 0.4825\n",
      "New best_val_rmse: 0.4825\n",
      "\n",
      "4 steps took 3.21 seconds\n",
      "Epoch: 4 batch_num: 0 val_rmse: 0.4826\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 4 val_rmse: 0.483\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 8 val_rmse: 0.4832\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.09 seconds\n",
      "Epoch: 4 batch_num: 12 val_rmse: 0.4834\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 4 batch_num: 16 val_rmse: 0.4838\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 20 val_rmse: 0.484\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.03 seconds\n",
      "Epoch: 4 batch_num: 24 val_rmse: 0.4843\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.01 seconds\n",
      "Epoch: 4 batch_num: 28 val_rmse: 0.485\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 32 val_rmse: 0.4859\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.04 seconds\n",
      "Epoch: 4 batch_num: 36 val_rmse: 0.486\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.4854\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.03 seconds\n",
      "Epoch: 4 batch_num: 44 val_rmse: 0.485\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 48 val_rmse: 0.4848\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.03 seconds\n",
      "Epoch: 4 batch_num: 52 val_rmse: 0.4847\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 56 val_rmse: 0.4846\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.16 seconds\n",
      "Epoch: 4 batch_num: 60 val_rmse: 0.4846\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 64 val_rmse: 0.4846\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.04 seconds\n",
      "Epoch: 4 batch_num: 68 val_rmse: 0.4846\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 72 val_rmse: 0.4846\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "4 steps took 3.04 seconds\n",
      "Epoch: 4 batch_num: 76 val_rmse: 0.4846\n",
      "Still best_val_rmse: 0.4825 (from epoch 3)\n",
      "\n",
      "Performance estimates:\n",
      "[0.502424615641487, 0.4629009152961681, 0.4534524158034372, 0.46491112537792356, 0.4563067646445377, 0.48253296556040165]\n",
      "Mean: 0.47042146705399257\n",
      "\n",
      "Fold 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8956\n",
      "New best_val_rmse: 0.8956\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.6828\n",
      "New best_val_rmse: 0.6828\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.5762\n",
      "New best_val_rmse: 0.5762\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.5601\n",
      "New best_val_rmse: 0.5601\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 1 batch_num: 1 val_rmse: 0.54\n",
      "New best_val_rmse: 0.54\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 17 val_rmse: 0.5483\n",
      "Still best_val_rmse: 0.54 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 33 val_rmse: 0.5229\n",
      "New best_val_rmse: 0.5229\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 49 val_rmse: 0.5392\n",
      "Still best_val_rmse: 0.5229 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 65 val_rmse: 0.5214\n",
      "New best_val_rmse: 0.5214\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 2 batch_num: 2 val_rmse: 0.5157\n",
      "New best_val_rmse: 0.5157\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 18 val_rmse: 0.4827\n",
      "New best_val_rmse: 0.4827\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 22 val_rmse: 0.4977\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "8 steps took 6.07 seconds\n",
      "Epoch: 2 batch_num: 30 val_rmse: 0.5063\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 46 val_rmse: 0.5033\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 62 val_rmse: 0.4932\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 2 batch_num: 70 val_rmse: 0.4897\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "4 steps took 3.06 seconds\n",
      "Epoch: 2 batch_num: 74 val_rmse: 0.5155\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 3 batch_num: 11 val_rmse: 0.5202\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 3 batch_num: 27 val_rmse: 0.5013\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 3 batch_num: 43 val_rmse: 0.4936\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "8 steps took 6.1 seconds\n",
      "Epoch: 3 batch_num: 51 val_rmse: 0.4985\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 3 batch_num: 59 val_rmse: 0.498\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "8 steps took 6.06 seconds\n",
      "Epoch: 3 batch_num: 67 val_rmse: 0.5008\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 4 batch_num: 4 val_rmse: 0.5022\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 4 batch_num: 20 val_rmse: 0.4956\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "8 steps took 6.07 seconds\n",
      "Epoch: 4 batch_num: 28 val_rmse: 0.4996\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 4 batch_num: 36 val_rmse: 0.5012\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 4 batch_num: 52 val_rmse: 0.495\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 4 batch_num: 60 val_rmse: 0.4956\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 4 batch_num: 68 val_rmse: 0.4957\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "8 steps took 6.06 seconds\n",
      "Epoch: 4 batch_num: 76 val_rmse: 0.4957\n",
      "Still best_val_rmse: 0.4827 (from epoch 2)\n",
      "\n",
      "Performance estimates:\n",
      "[0.502424615641487, 0.4629009152961681, 0.4534524158034372, 0.46491112537792356, 0.4563067646445377, 0.48253296556040165, 0.48268188083289426]\n",
      "Mean: 0.4721729547366928\n",
      "\n",
      "Fold 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9201\n",
      "New best_val_rmse: 0.9201\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7405\n",
      "New best_val_rmse: 0.7405\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6124\n",
      "New best_val_rmse: 0.6124\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.5926\n",
      "New best_val_rmse: 0.5926\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 1 batch_num: 1 val_rmse: 0.6132\n",
      "Still best_val_rmse: 0.5926 (from epoch 0)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 17 val_rmse: 0.5168\n",
      "New best_val_rmse: 0.5168\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 33 val_rmse: 0.4928\n",
      "New best_val_rmse: 0.4928\n",
      "\n",
      "8 steps took 6.11 seconds\n",
      "Epoch: 1 batch_num: 41 val_rmse: 0.5293\n",
      "Still best_val_rmse: 0.4928 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 57 val_rmse: 0.5104\n",
      "Still best_val_rmse: 0.4928 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 73 val_rmse: 0.56\n",
      "Still best_val_rmse: 0.4928 (from epoch 1)\n",
      "\n",
      "16 steps took 12.4 seconds\n",
      "Epoch: 2 batch_num: 10 val_rmse: 0.5145\n",
      "Still best_val_rmse: 0.4928 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 26 val_rmse: 0.4983\n",
      "Still best_val_rmse: 0.4928 (from epoch 1)\n",
      "\n",
      "8 steps took 6.12 seconds\n",
      "Epoch: 2 batch_num: 34 val_rmse: 0.4859\n",
      "New best_val_rmse: 0.4859\n",
      "\n",
      "4 steps took 3.06 seconds\n",
      "Epoch: 2 batch_num: 38 val_rmse: 0.506\n",
      "Still best_val_rmse: 0.4859 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 54 val_rmse: 0.5106\n",
      "Still best_val_rmse: 0.4859 (from epoch 2)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 70 val_rmse: 0.4934\n",
      "Still best_val_rmse: 0.4859 (from epoch 2)\n",
      "\n",
      "8 steps took 6.1 seconds\n",
      "Epoch: 2 batch_num: 78 val_rmse: 0.5068\n",
      "Still best_val_rmse: 0.4859 (from epoch 2)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 3 batch_num: 15 val_rmse: 0.4926\n",
      "Still best_val_rmse: 0.4859 (from epoch 2)\n",
      "\n",
      "8 steps took 6.05 seconds\n",
      "Epoch: 3 batch_num: 23 val_rmse: 0.4909\n",
      "Still best_val_rmse: 0.4859 (from epoch 2)\n",
      "\n",
      "8 steps took 6.16 seconds\n",
      "Epoch: 3 batch_num: 31 val_rmse: 0.4856\n",
      "New best_val_rmse: 0.4856\n",
      "\n",
      "4 steps took 3.05 seconds\n",
      "Epoch: 3 batch_num: 35 val_rmse: 0.5041\n",
      "Still best_val_rmse: 0.4856 (from epoch 3)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 3 batch_num: 51 val_rmse: 0.4947\n",
      "Still best_val_rmse: 0.4856 (from epoch 3)\n",
      "\n",
      "8 steps took 6.23 seconds\n",
      "Epoch: 3 batch_num: 59 val_rmse: 0.4945\n",
      "Still best_val_rmse: 0.4856 (from epoch 3)\n",
      "\n",
      "8 steps took 6.04 seconds\n",
      "Epoch: 3 batch_num: 67 val_rmse: 0.4838\n",
      "New best_val_rmse: 0.4838\n",
      "\n",
      "4 steps took 3.03 seconds\n",
      "Epoch: 3 batch_num: 71 val_rmse: 0.4829\n",
      "New best_val_rmse: 0.4829\n",
      "\n",
      "4 steps took 3.09 seconds\n",
      "Epoch: 3 batch_num: 75 val_rmse: 0.4899\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.25 seconds\n",
      "Epoch: 4 batch_num: 0 val_rmse: 0.4903\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "8 steps took 6.14 seconds\n",
      "Epoch: 4 batch_num: 8 val_rmse: 0.4836\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 12 val_rmse: 0.4835\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.03 seconds\n",
      "Epoch: 4 batch_num: 16 val_rmse: 0.4837\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 20 val_rmse: 0.4848\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 24 val_rmse: 0.4855\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 28 val_rmse: 0.487\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.04 seconds\n",
      "Epoch: 4 batch_num: 32 val_rmse: 0.4883\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 36 val_rmse: 0.4884\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.4871\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 44 val_rmse: 0.4874\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.05 seconds\n",
      "Epoch: 4 batch_num: 48 val_rmse: 0.488\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 52 val_rmse: 0.4878\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.08 seconds\n",
      "Epoch: 4 batch_num: 56 val_rmse: 0.4878\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.03 seconds\n",
      "Epoch: 4 batch_num: 60 val_rmse: 0.4877\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.04 seconds\n",
      "Epoch: 4 batch_num: 64 val_rmse: 0.4876\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.03 seconds\n",
      "Epoch: 4 batch_num: 68 val_rmse: 0.4876\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.04 seconds\n",
      "Epoch: 4 batch_num: 72 val_rmse: 0.4876\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 4 batch_num: 76 val_rmse: 0.4876\n",
      "Still best_val_rmse: 0.4829 (from epoch 3)\n",
      "\n",
      "Performance estimates:\n",
      "[0.502424615641487, 0.4629009152961681, 0.4534524158034372, 0.46491112537792356, 0.4563067646445377, 0.48253296556040165, 0.48268188083289426, 0.4828545424002557]\n",
      "Mean: 0.4735081531946382\n",
      "\n",
      "Fold 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.0 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.8554\n",
      "New best_val_rmse: 0.8554\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.6714\n",
      "New best_val_rmse: 0.6714\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.5399\n",
      "New best_val_rmse: 0.5399\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.5151\n",
      "New best_val_rmse: 0.5151\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 1 batch_num: 1 val_rmse: 0.4973\n",
      "New best_val_rmse: 0.4973\n",
      "\n",
      "8 steps took 6.13 seconds\n",
      "Epoch: 1 batch_num: 9 val_rmse: 0.5624\n",
      "Still best_val_rmse: 0.4973 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 25 val_rmse: 0.52\n",
      "Still best_val_rmse: 0.4973 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 41 val_rmse: 0.4766\n",
      "New best_val_rmse: 0.4766\n",
      "\n",
      "2 steps took 1.52 seconds\n",
      "Epoch: 1 batch_num: 43 val_rmse: 0.4808\n",
      "Still best_val_rmse: 0.4766 (from epoch 1)\n",
      "\n",
      "4 steps took 3.1 seconds\n",
      "Epoch: 1 batch_num: 47 val_rmse: 0.5185\n",
      "Still best_val_rmse: 0.4766 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 63 val_rmse: 0.4536\n",
      "New best_val_rmse: 0.4536\n",
      "\n",
      "1 steps took 0.79 seconds\n",
      "Epoch: 1 batch_num: 64 val_rmse: 0.4622\n",
      "Still best_val_rmse: 0.4536 (from epoch 1)\n",
      "\n",
      "1 steps took 0.791 seconds\n",
      "Epoch: 1 batch_num: 65 val_rmse: 0.4762\n",
      "Still best_val_rmse: 0.4536 (from epoch 1)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 1 batch_num: 67 val_rmse: 0.4486\n",
      "New best_val_rmse: 0.4486\n",
      "\n",
      "1 steps took 0.785 seconds\n",
      "Epoch: 1 batch_num: 68 val_rmse: 0.5049\n",
      "Still best_val_rmse: 0.4486 (from epoch 1)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 2 batch_num: 5 val_rmse: 0.4478\n",
      "New best_val_rmse: 0.4478\n",
      "\n",
      "1 steps took 0.798 seconds\n",
      "Epoch: 2 batch_num: 6 val_rmse: 0.4454\n",
      "New best_val_rmse: 0.4454\n",
      "\n",
      "1 steps took 0.768 seconds\n",
      "Epoch: 2 batch_num: 7 val_rmse: 0.4442\n",
      "New best_val_rmse: 0.4442\n",
      "\n",
      "1 steps took 0.771 seconds\n",
      "Epoch: 2 batch_num: 8 val_rmse: 0.4443\n",
      "Still best_val_rmse: 0.4442 (from epoch 2)\n",
      "\n",
      "1 steps took 0.768 seconds\n",
      "Epoch: 2 batch_num: 9 val_rmse: 0.4446\n",
      "Still best_val_rmse: 0.4442 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 2 batch_num: 10 val_rmse: 0.4417\n",
      "New best_val_rmse: 0.4417\n",
      "\n",
      "1 steps took 0.798 seconds\n",
      "Epoch: 2 batch_num: 11 val_rmse: 0.4435\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 2 batch_num: 12 val_rmse: 0.4425\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 2 batch_num: 13 val_rmse: 0.4419\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 2 batch_num: 14 val_rmse: 0.4457\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.782 seconds\n",
      "Epoch: 2 batch_num: 15 val_rmse: 0.4502\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 16 val_rmse: 0.4653\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 17 val_rmse: 0.4654\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.806 seconds\n",
      "Epoch: 2 batch_num: 18 val_rmse: 0.4428\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 2 batch_num: 19 val_rmse: 0.4509\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 2 batch_num: 20 val_rmse: 0.4594\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 2 batch_num: 21 val_rmse: 0.4444\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 2 batch_num: 22 val_rmse: 0.4832\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "4 steps took 3.02 seconds\n",
      "Epoch: 2 batch_num: 26 val_rmse: 0.4456\n",
      "Still best_val_rmse: 0.4417 (from epoch 2)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 2 batch_num: 27 val_rmse: 0.4416\n",
      "New best_val_rmse: 0.4416\n",
      "\n",
      "1 steps took 0.765 seconds\n",
      "Epoch: 2 batch_num: 28 val_rmse: 0.4415\n",
      "New best_val_rmse: 0.4415\n",
      "\n",
      "1 steps took 0.768 seconds\n",
      "Epoch: 2 batch_num: 29 val_rmse: 0.4494\n",
      "Still best_val_rmse: 0.4415 (from epoch 2)\n",
      "\n",
      "1 steps took 0.832 seconds\n",
      "Epoch: 2 batch_num: 30 val_rmse: 0.4565\n",
      "Still best_val_rmse: 0.4415 (from epoch 2)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 2 batch_num: 31 val_rmse: 0.4425\n",
      "Still best_val_rmse: 0.4415 (from epoch 2)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 2 batch_num: 32 val_rmse: 0.4378\n",
      "New best_val_rmse: 0.4378\n",
      "\n",
      "1 steps took 0.791 seconds\n",
      "Epoch: 2 batch_num: 33 val_rmse: 0.4424\n",
      "Still best_val_rmse: 0.4378 (from epoch 2)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 2 batch_num: 34 val_rmse: 0.439\n",
      "Still best_val_rmse: 0.4378 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 35 val_rmse: 0.4594\n",
      "Still best_val_rmse: 0.4378 (from epoch 2)\n",
      "\n",
      "1 steps took 0.787 seconds\n",
      "Epoch: 2 batch_num: 36 val_rmse: 0.4502\n",
      "Still best_val_rmse: 0.4378 (from epoch 2)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 2 batch_num: 37 val_rmse: 0.4365\n",
      "New best_val_rmse: 0.4365\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 2 batch_num: 38 val_rmse: 0.436\n",
      "New best_val_rmse: 0.436\n",
      "\n",
      "1 steps took 0.841 seconds\n",
      "Epoch: 2 batch_num: 39 val_rmse: 0.4375\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 2 batch_num: 40 val_rmse: 0.4376\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 41 val_rmse: 0.4368\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.772 seconds\n",
      "Epoch: 2 batch_num: 42 val_rmse: 0.4364\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 43 val_rmse: 0.4374\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 2 batch_num: 44 val_rmse: 0.4389\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.784 seconds\n",
      "Epoch: 2 batch_num: 45 val_rmse: 0.4407\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 2 batch_num: 46 val_rmse: 0.4422\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 2 batch_num: 47 val_rmse: 0.4477\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 2 batch_num: 48 val_rmse: 0.4616\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.784 seconds\n",
      "Epoch: 2 batch_num: 49 val_rmse: 0.4714\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 51 val_rmse: 0.4691\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 52 val_rmse: 0.475\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 2 batch_num: 54 val_rmse: 0.4717\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 56 val_rmse: 0.4572\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 2 batch_num: 57 val_rmse: 0.4528\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 2 batch_num: 58 val_rmse: 0.4561\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 2 batch_num: 59 val_rmse: 0.4582\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 2 batch_num: 60 val_rmse: 0.4578\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 2 batch_num: 61 val_rmse: 0.4569\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.765 seconds\n",
      "Epoch: 2 batch_num: 62 val_rmse: 0.4623\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 2 batch_num: 63 val_rmse: 0.4691\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 2 batch_num: 64 val_rmse: 0.46\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 2 batch_num: 65 val_rmse: 0.4563\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 66 val_rmse: 0.4663\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 2 batch_num: 67 val_rmse: 0.4703\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 69 val_rmse: 0.4723\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "2 steps took 1.51 seconds\n",
      "Epoch: 2 batch_num: 71 val_rmse: 0.4503\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 2 batch_num: 72 val_rmse: 0.4378\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 2 batch_num: 73 val_rmse: 0.4381\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.772 seconds\n",
      "Epoch: 2 batch_num: 74 val_rmse: 0.4393\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 2 batch_num: 75 val_rmse: 0.4404\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 2 batch_num: 76 val_rmse: 0.4407\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 2 batch_num: 77 val_rmse: 0.4405\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 2 batch_num: 78 val_rmse: 0.4438\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 1.0 seconds\n",
      "Epoch: 3 batch_num: 0 val_rmse: 0.4492\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 1 val_rmse: 0.4434\n",
      "Still best_val_rmse: 0.436 (from epoch 2)\n",
      "\n",
      "1 steps took 0.768 seconds\n",
      "Epoch: 3 batch_num: 2 val_rmse: 0.4354\n",
      "New best_val_rmse: 0.4354\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 3 val_rmse: 0.4394\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 4 val_rmse: 0.4427\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 3 batch_num: 5 val_rmse: 0.4421\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 3 batch_num: 6 val_rmse: 0.447\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 3 batch_num: 7 val_rmse: 0.4746\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "2 steps took 1.53 seconds\n",
      "Epoch: 3 batch_num: 9 val_rmse: 0.4857\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "4 steps took 3.06 seconds\n",
      "Epoch: 3 batch_num: 13 val_rmse: 0.4568\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 3 batch_num: 14 val_rmse: 0.4434\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.772 seconds\n",
      "Epoch: 3 batch_num: 15 val_rmse: 0.4382\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 16 val_rmse: 0.4508\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 17 val_rmse: 0.4673\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 18 val_rmse: 0.4695\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.781 seconds\n",
      "Epoch: 3 batch_num: 19 val_rmse: 0.4497\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 20 val_rmse: 0.4366\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 21 val_rmse: 0.4393\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.762 seconds\n",
      "Epoch: 3 batch_num: 22 val_rmse: 0.44\n",
      "Still best_val_rmse: 0.4354 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 23 val_rmse: 0.4349\n",
      "New best_val_rmse: 0.4349\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 24 val_rmse: 0.4357\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.772 seconds\n",
      "Epoch: 3 batch_num: 25 val_rmse: 0.4428\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.766 seconds\n",
      "Epoch: 3 batch_num: 26 val_rmse: 0.4535\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.762 seconds\n",
      "Epoch: 3 batch_num: 27 val_rmse: 0.4498\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 28 val_rmse: 0.4444\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.764 seconds\n",
      "Epoch: 3 batch_num: 29 val_rmse: 0.4379\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 3 batch_num: 30 val_rmse: 0.4355\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 3 batch_num: 31 val_rmse: 0.4364\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.807 seconds\n",
      "Epoch: 3 batch_num: 32 val_rmse: 0.4383\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 3 batch_num: 33 val_rmse: 0.4371\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 3 batch_num: 34 val_rmse: 0.4369\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 35 val_rmse: 0.4383\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 3 batch_num: 36 val_rmse: 0.4393\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 37 val_rmse: 0.4393\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 3 batch_num: 38 val_rmse: 0.4367\n",
      "Still best_val_rmse: 0.4349 (from epoch 3)\n",
      "\n",
      "1 steps took 0.8 seconds\n",
      "Epoch: 3 batch_num: 39 val_rmse: 0.4345\n",
      "New best_val_rmse: 0.4345\n",
      "\n",
      "1 steps took 0.766 seconds\n",
      "Epoch: 3 batch_num: 40 val_rmse: 0.4331\n",
      "New best_val_rmse: 0.4331\n",
      "\n",
      "1 steps took 0.813 seconds\n",
      "Epoch: 3 batch_num: 41 val_rmse: 0.4333\n",
      "Still best_val_rmse: 0.4331 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 42 val_rmse: 0.4332\n",
      "Still best_val_rmse: 0.4331 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 43 val_rmse: 0.4327\n",
      "New best_val_rmse: 0.4327\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 44 val_rmse: 0.4325\n",
      "New best_val_rmse: 0.4325\n",
      "\n",
      "1 steps took 0.802 seconds\n",
      "Epoch: 3 batch_num: 45 val_rmse: 0.4339\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.764 seconds\n",
      "Epoch: 3 batch_num: 46 val_rmse: 0.434\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.762 seconds\n",
      "Epoch: 3 batch_num: 47 val_rmse: 0.4335\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 48 val_rmse: 0.4336\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 49 val_rmse: 0.4343\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.784 seconds\n",
      "Epoch: 3 batch_num: 50 val_rmse: 0.4353\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 51 val_rmse: 0.4368\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 52 val_rmse: 0.4387\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 3 batch_num: 53 val_rmse: 0.4419\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.766 seconds\n",
      "Epoch: 3 batch_num: 54 val_rmse: 0.4428\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 55 val_rmse: 0.4387\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 3 batch_num: 56 val_rmse: 0.437\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 3 batch_num: 57 val_rmse: 0.4361\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 58 val_rmse: 0.4361\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 59 val_rmse: 0.4365\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.783 seconds\n",
      "Epoch: 3 batch_num: 60 val_rmse: 0.4366\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.774 seconds\n",
      "Epoch: 3 batch_num: 61 val_rmse: 0.4382\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 62 val_rmse: 0.443\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 63 val_rmse: 0.4472\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 3 batch_num: 64 val_rmse: 0.4483\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 3 batch_num: 65 val_rmse: 0.4504\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 3 batch_num: 66 val_rmse: 0.4532\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 67 val_rmse: 0.4505\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.815 seconds\n",
      "Epoch: 3 batch_num: 68 val_rmse: 0.4453\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 69 val_rmse: 0.4416\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.783 seconds\n",
      "Epoch: 3 batch_num: 70 val_rmse: 0.4414\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 3 batch_num: 71 val_rmse: 0.4415\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 72 val_rmse: 0.4416\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 73 val_rmse: 0.4416\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 3 batch_num: 74 val_rmse: 0.4425\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.771 seconds\n",
      "Epoch: 3 batch_num: 75 val_rmse: 0.444\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 3 batch_num: 76 val_rmse: 0.4439\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 3 batch_num: 77 val_rmse: 0.446\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.774 seconds\n",
      "Epoch: 3 batch_num: 78 val_rmse: 0.4475\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.94 seconds\n",
      "Epoch: 4 batch_num: 0 val_rmse: 0.4452\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.794 seconds\n",
      "Epoch: 4 batch_num: 1 val_rmse: 0.4428\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 2 val_rmse: 0.4395\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 3 val_rmse: 0.4374\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 4 batch_num: 4 val_rmse: 0.4364\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 5 val_rmse: 0.436\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 4 batch_num: 6 val_rmse: 0.436\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 7 val_rmse: 0.4359\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 8 val_rmse: 0.4359\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 9 val_rmse: 0.4364\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.777 seconds\n",
      "Epoch: 4 batch_num: 10 val_rmse: 0.4373\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.785 seconds\n",
      "Epoch: 4 batch_num: 11 val_rmse: 0.4387\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 12 val_rmse: 0.4411\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 13 val_rmse: 0.4428\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.764 seconds\n",
      "Epoch: 4 batch_num: 14 val_rmse: 0.4437\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 4 batch_num: 15 val_rmse: 0.4432\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 16 val_rmse: 0.442\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.78 seconds\n",
      "Epoch: 4 batch_num: 17 val_rmse: 0.4407\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 4 batch_num: 18 val_rmse: 0.4402\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 19 val_rmse: 0.44\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.789 seconds\n",
      "Epoch: 4 batch_num: 20 val_rmse: 0.4396\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.784 seconds\n",
      "Epoch: 4 batch_num: 21 val_rmse: 0.4392\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 22 val_rmse: 0.4389\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 23 val_rmse: 0.4386\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.769 seconds\n",
      "Epoch: 4 batch_num: 24 val_rmse: 0.4385\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 25 val_rmse: 0.4386\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 26 val_rmse: 0.4388\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 27 val_rmse: 0.4391\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.761 seconds\n",
      "Epoch: 4 batch_num: 28 val_rmse: 0.4395\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 29 val_rmse: 0.44\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.771 seconds\n",
      "Epoch: 4 batch_num: 30 val_rmse: 0.4405\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.817 seconds\n",
      "Epoch: 4 batch_num: 31 val_rmse: 0.4407\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.762 seconds\n",
      "Epoch: 4 batch_num: 32 val_rmse: 0.441\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 33 val_rmse: 0.4411\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 34 val_rmse: 0.4411\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 35 val_rmse: 0.4409\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 36 val_rmse: 0.4405\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 37 val_rmse: 0.4403\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.78 seconds\n",
      "Epoch: 4 batch_num: 38 val_rmse: 0.4404\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 39 val_rmse: 0.4402\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.797 seconds\n",
      "Epoch: 4 batch_num: 40 val_rmse: 0.4402\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.788 seconds\n",
      "Epoch: 4 batch_num: 41 val_rmse: 0.4401\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 42 val_rmse: 0.4398\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 43 val_rmse: 0.4396\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 4 batch_num: 44 val_rmse: 0.4392\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.775 seconds\n",
      "Epoch: 4 batch_num: 45 val_rmse: 0.4389\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 46 val_rmse: 0.4387\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 4 batch_num: 47 val_rmse: 0.4386\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 48 val_rmse: 0.4387\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 49 val_rmse: 0.4388\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 50 val_rmse: 0.4388\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.791 seconds\n",
      "Epoch: 4 batch_num: 51 val_rmse: 0.4388\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.779 seconds\n",
      "Epoch: 4 batch_num: 52 val_rmse: 0.4388\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 53 val_rmse: 0.4387\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 54 val_rmse: 0.4387\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.763 seconds\n",
      "Epoch: 4 batch_num: 55 val_rmse: 0.4388\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.76 seconds\n",
      "Epoch: 4 batch_num: 56 val_rmse: 0.4389\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 57 val_rmse: 0.439\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 58 val_rmse: 0.4391\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.774 seconds\n",
      "Epoch: 4 batch_num: 59 val_rmse: 0.4392\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 60 val_rmse: 0.4393\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.782 seconds\n",
      "Epoch: 4 batch_num: 61 val_rmse: 0.4393\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 62 val_rmse: 0.4393\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 63 val_rmse: 0.4393\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.756 seconds\n",
      "Epoch: 4 batch_num: 64 val_rmse: 0.4393\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 65 val_rmse: 0.4393\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.779 seconds\n",
      "Epoch: 4 batch_num: 66 val_rmse: 0.4392\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.764 seconds\n",
      "Epoch: 4 batch_num: 67 val_rmse: 0.4392\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.758 seconds\n",
      "Epoch: 4 batch_num: 68 val_rmse: 0.4392\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.753 seconds\n",
      "Epoch: 4 batch_num: 69 val_rmse: 0.4391\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.755 seconds\n",
      "Epoch: 4 batch_num: 70 val_rmse: 0.4391\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.757 seconds\n",
      "Epoch: 4 batch_num: 71 val_rmse: 0.4391\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.766 seconds\n",
      "Epoch: 4 batch_num: 72 val_rmse: 0.4391\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.775 seconds\n",
      "Epoch: 4 batch_num: 73 val_rmse: 0.439\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.759 seconds\n",
      "Epoch: 4 batch_num: 74 val_rmse: 0.439\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 75 val_rmse: 0.439\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.752 seconds\n",
      "Epoch: 4 batch_num: 76 val_rmse: 0.439\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.772 seconds\n",
      "Epoch: 4 batch_num: 77 val_rmse: 0.439\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "1 steps took 0.754 seconds\n",
      "Epoch: 4 batch_num: 78 val_rmse: 0.439\n",
      "Still best_val_rmse: 0.4325 (from epoch 3)\n",
      "\n",
      "Performance estimates:\n",
      "[0.502424615641487, 0.4629009152961681, 0.4534524158034372, 0.46491112537792356, 0.4563067646445377, 0.48253296556040165, 0.48268188083289426, 0.4828545424002557, 0.4324853787262586]\n",
      "Mean: 0.468950067142596\n",
      "\n",
      "Fold 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 steps took 13.1 seconds\n",
      "Epoch: 0 batch_num: 16 val_rmse: 0.9628\n",
      "New best_val_rmse: 0.9628\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 0.7367\n",
      "New best_val_rmse: 0.7367\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 48 val_rmse: 0.6691\n",
      "New best_val_rmse: 0.6691\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 0.7469\n",
      "Still best_val_rmse: 0.6691 (from epoch 0)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 1 batch_num: 1 val_rmse: 0.5794\n",
      "New best_val_rmse: 0.5794\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 17 val_rmse: 0.5706\n",
      "New best_val_rmse: 0.5706\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 1 batch_num: 33 val_rmse: 0.5202\n",
      "New best_val_rmse: 0.5202\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 49 val_rmse: 0.4967\n",
      "New best_val_rmse: 0.4967\n",
      "\n",
      "8 steps took 6.07 seconds\n",
      "Epoch: 1 batch_num: 57 val_rmse: 0.5142\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 1 batch_num: 73 val_rmse: 0.5189\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 10 val_rmse: 0.5334\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 26 val_rmse: 0.5069\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 42 val_rmse: 0.5259\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 2 batch_num: 58 val_rmse: 0.5367\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 2 batch_num: 74 val_rmse: 0.5107\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 3 batch_num: 11 val_rmse: 0.5331\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 3 batch_num: 27 val_rmse: 0.5164\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 3 batch_num: 43 val_rmse: 0.514\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 3 batch_num: 59 val_rmse: 0.5103\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.0 seconds\n",
      "Epoch: 3 batch_num: 75 val_rmse: 0.501\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.3 seconds\n",
      "Epoch: 4 batch_num: 12 val_rmse: 0.5092\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 4 batch_num: 28 val_rmse: 0.5081\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 4 batch_num: 44 val_rmse: 0.5115\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.1 seconds\n",
      "Epoch: 4 batch_num: 60 val_rmse: 0.5104\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "16 steps took 12.2 seconds\n",
      "Epoch: 4 batch_num: 76 val_rmse: 0.5102\n",
      "Still best_val_rmse: 0.4967 (from epoch 1)\n",
      "\n",
      "Performance estimates:\n",
      "[0.502424615641487, 0.4629009152961681, 0.4534524158034372, 0.46491112537792356, 0.4563067646445377, 0.48253296556040165, 0.48268188083289426, 0.4828545424002557, 0.4324853787262586, 0.49674317841162713]\n",
      "Mean: 0.4717293782694991\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "# 随机种子设为1000\n",
    "SEED = 1000\n",
    "list_val_rmse = []\n",
    "# 使用交叉验证方法，能更好的抗过拟合\n",
    "kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
    "# \n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)):    \n",
    "    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n",
    "    model_path = f\"model_{fold + 1}.pth\"\n",
    "        \n",
    "    set_random_seed(SEED + fold)\n",
    "    # 数据集处理\n",
    "    train_dataset = LitDataset(train_df.loc[train_indices])    \n",
    "    val_dataset = LitDataset(train_df.loc[val_indices])    \n",
    "    # 模型读取数据集    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                              drop_last=True, shuffle=True, num_workers=2)    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                            drop_last=False, shuffle=False, num_workers=2)    \n",
    "        \n",
    "    set_random_seed(SEED + fold)    \n",
    "    \n",
    "    model = LitModel().to(DEVICE)\n",
    "    # 优化模型\n",
    "    optimizer = create_optimizer(model)\n",
    "    # 优化器衰减方式\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_training_steps=NUM_EPOCHS * len(train_loader),\n",
    "        num_warmup_steps=50)    \n",
    "    # 验证rmse损失做成列表\n",
    "    list_val_rmse.append(train(model, model_path, train_loader,\n",
    "                               val_loader, optimizer, scheduler=scheduler))\n",
    "    # 删除模型\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"\\nPerformance estimates:\")\n",
    "    print(list_val_rmse)\n",
    "    print(\"Mean:\", np.array(list_val_rmse).mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.681736,
     "end_time": "2021-07-05T12:24:27.233729",
     "exception": false,
     "start_time": "2021-07-05T12:24:26.551993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:24:28.634721Z",
     "iopub.status.busy": "2021-07-05T12:24:28.633580Z",
     "iopub.status.idle": "2021-07-05T12:24:28.663073Z",
     "shell.execute_reply": "2021-07-05T12:24:28.662550Z"
    },
    "papermill": {
     "duration": 0.73898,
     "end_time": "2021-07-05T12:24:28.663234",
     "exception": false,
     "start_time": "2021-07-05T12:24:27.924254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 测试数据\n",
    "test_dataset = LitDataset(test_df, inference_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:24:30.030914Z",
     "iopub.status.busy": "2021-07-05T12:24:30.029523Z",
     "iopub.status.idle": "2021-07-05T12:25:32.162513Z",
     "shell.execute_reply": "2021-07-05T12:25:32.161586Z"
    },
    "papermill": {
     "duration": 62.820022,
     "end_time": "2021-07-05T12:25:32.162657",
     "exception": false,
     "start_time": "2021-07-05T12:24:29.342635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_9.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 建立一个空数组用于保存预测数据 \n",
    "all_predictions = np.zeros((len(list_val_rmse), len(test_df)))\n",
    "# 处理测试数据\n",
    "test_dataset = LitDataset(test_df, inference_only=True)\n",
    "# 将测试数据转换成张量导入模型中预测\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                         drop_last=False, shuffle=False, num_workers=2)\n",
    "# \n",
    "for index in range(len(list_val_rmse)):            \n",
    "    model_path = f\"model_{index + 1}.pth\"\n",
    "    print(f\"\\nUsing {model_path}\")\n",
    "    # 模型                    \n",
    "    model = LitModel()\n",
    "    # 读取模型参数\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    # 将模型参数导入GPU中\n",
    "    model.to(DEVICE)\n",
    "    # 将预测列表到如数组\n",
    "    all_predictions[index] = predict(model, test_loader)\n",
    "    # 删除模型\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:25:33.560550Z",
     "iopub.status.busy": "2021-07-05T12:25:33.559962Z",
     "iopub.status.idle": "2021-07-05T12:25:34.794054Z",
     "shell.execute_reply": "2021-07-05T12:25:34.793489Z"
    },
    "papermill": {
     "duration": 1.940475,
     "end_time": "2021-07-05T12:25:34.794211",
     "exception": false,
     "start_time": "2021-07-05T12:25:32.853736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id    target\n",
      "0  c0f722661 -0.419028\n",
      "1  f0953f0a5 -0.668754\n",
      "2  0df072751 -0.375996\n",
      "3  04caf4e0c -2.366732\n",
      "4  0e63f8bea -1.768860\n",
      "5  12537fe78 -1.326430\n",
      "6  965e592c0  0.058625\n"
     ]
    }
   ],
   "source": [
    "# 将预测结果导入到csv中。\n",
    "predictions = all_predictions.mean(axis=0)\n",
    "submission_df.target = predictions\n",
    "print(submission_df)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5705.327098,
   "end_time": "2021-07-05T12:25:38.423795",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-05T10:50:33.096697",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
